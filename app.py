from flask import Flask, render_template, request, render_template_string, redirect, url_for, jsonify, Response, session, g
from flask_mysqldb import MySQL
from werkzeug.security import generate_password_hash, check_password_hash
from config import Config  # å¯¼å…¥é…ç½®æ–‡ä»¶
import json
import time
import threading
from queue import Queue
import torch
import os
import sys
from io import StringIO
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éGUIåç«¯
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from datetime import timedelta, datetime
from functools import wraps
import uuid as uuid_module
import mysql.connector as mysql_connector

# ========== å¯¼å…¥è®¤è¯æ¨¡å— ==========
from auth_module import (
    login_required, 
    UserManager, 
    TrainingSessionManager,
    FileManager,
    get_user_plot_dir,
    get_user_checkpoint_dir,
    set_user_session,
    clear_user_session,
    get_current_user_id,
    get_current_username,
    safe_join_path
)

# é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# å¯¼å…¥ RL4CO ç›¸å…³æ¨¡å—
try:
    from rl4co.envs import TSPEnv, CVRPEnv
    from rl4co.models import AttentionModelPolicy, REINFORCE
    from rl4co.utils.trainer import RL4COTrainer
    from lightning.pytorch.callbacks import Callback
    RL4CO_AVAILABLE = True
except ImportError:
    RL4CO_AVAILABLE = False
    print("è­¦å‘Š: RL4CO åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼")

app = Flask(__name__)
# åŠ è½½é…ç½®
app.config.from_object(Config)

# ========== æ·»åŠ  SECRET_KEY é…ç½®ï¼ˆç”¨æˆ·è®¤è¯å¿…éœ€ï¼‰ ==========
app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY') or 'rl4co-display-secret-key-2024-change-in-production'
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=7)

mysql = MySQL(app)

# ========== æ•°æ®åº“è¿æ¥ç®¡ç†ï¼ˆä½¿ç”¨ Flask è¯·æ±‚ä¸Šä¸‹æ–‡ï¼‰ ==========
def get_db():
    """è·å–å½“å‰è¯·æ±‚çš„æ•°æ®åº“è¿æ¥ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    if 'db' not in g:
        try:
            g.db = mysql_connector.connect(
                host=Config.MYSQL_HOST,
                user=Config.MYSQL_USER,
                password=Config.MYSQL_PASSWORD,
                database=Config.MYSQL_DB,
                autocommit=True
            )
        except Exception as e:
            print(f"âœ— æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            g.db = None
    return g.db

@app.teardown_appcontext
def close_db(error):
    """åœ¨è¯·æ±‚ç»“æŸæ—¶å…³é—­æ•°æ®åº“è¿æ¥"""
    db = g.pop('db', None)
    if db is not None:
        try:
            db.close()
        except:
            pass

def get_user_manager():
    """è·å–å½“å‰è¯·æ±‚çš„ UserManager å®ä¾‹"""
    db = get_db()
    if db is None:
        return None
    if 'user_manager' not in g:
        g.user_manager = UserManager(db)
    return g.user_manager

def get_session_manager():
    """è·å–å½“å‰è¯·æ±‚çš„ TrainingSessionManager å®ä¾‹"""
    db = get_db()
    if db is None:
        return None
    if 'session_manager' not in g:
        g.session_manager = TrainingSessionManager(db)
    return g.session_manager

def get_file_manager():
    """è·å–å½“å‰è¯·æ±‚çš„ FileManager å®ä¾‹"""
    db = get_db()
    if db is None:
        return None
    if 'file_manager' not in g:
        g.file_manager = FileManager(db)
    return g.file_manager

def get_background_db():
    """ä¸ºåå°ä»»åŠ¡åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥ï¼ˆä¸ä½¿ç”¨ Flask g å¯¹è±¡ï¼‰"""
    try:
        db = mysql_connector.connect(
            host=Config.MYSQL_HOST,
            user=Config.MYSQL_USER,
            password=Config.MYSQL_PASSWORD,
            database=Config.MYSQL_DB,
            autocommit=True
        )
        return db
    except Exception as e:
        print(f"âœ— åå°æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        return None

print("âœ“ ç”¨æˆ·è®¤è¯æ¨¡å—ï¼ˆè¯·æ±‚ä¸Šä¸‹æ–‡æ¨¡å¼ï¼‰é…ç½®å®Œæˆ")

# ç”¨äºå­˜å‚¨è®­ç»ƒçŠ¶æ€å’Œè¿›åº¦çš„å…¨å±€å­—å…¸
training_status = {}
training_queues = {}

# åˆ›å»ºè¾“å‡ºç›®å½•
PLOTS_DIR = "static/model_plots"
CHECKPOINTS_DIR = "checkpoints"
os.makedirs(PLOTS_DIR, exist_ok=True)
os.makedirs(CHECKPOINTS_DIR, exist_ok=True)

# ========== æ€§èƒ½ä¼˜åŒ–ï¼šAPIå“åº”ç¼“å­˜ ==========
class SimpleCache:
    """ç®€å•çš„APIå“åº”ç¼“å­˜"""
    def __init__(self, timeout=300):
        self.cache = {}
        self.timeout = timeout
    
    def get(self, key):
        if key in self.cache:
            data, timestamp = self.cache[key]
            if time.time() - timestamp < self.timeout:
                return data
            else:
                del self.cache[key]
        return None
    
    def set(self, key, value):
        self.cache[key] = (value, time.time())
    
    def clear(self):
        self.cache.clear()

api_cache = SimpleCache(timeout=300)  # 5åˆ†é’Ÿç¼“å­˜

def cached_api(key_prefix=''):
    """APIç¼“å­˜è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            user_id = get_current_user_id()
            cache_key = f"{key_prefix}:{user_id}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = api_cache.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # è°ƒç”¨åŸå‡½æ•°
            result = f(*args, **kwargs)
            
            # ç¼“å­˜ç»“æœï¼ˆä»…ç¼“å­˜æˆåŠŸçš„å“åº”ï¼‰
            if isinstance(result, tuple):
                data, status_code = result if len(result) == 2 else (result, 200)
                if status_code == 200:
                    api_cache.set(cache_key, result)
            else:
                api_cache.set(cache_key, result)
            
            return result
        return decorated_function
    return decorator


def create_route_animation(td, actions, save_path, title="è·¯çº¿ç”Ÿæˆè¿‡ç¨‹", fps=2):
    """
    åˆ›å»ºTSPè·¯çº¿é€æ­¥ç”Ÿæˆçš„åŠ¨æ€GIF
    
    å‚æ•°:
        td: TensorDictï¼ŒåŒ…å«åŸå¸‚åæ ‡ç­‰ä¿¡æ¯
        actions: numpyæ•°ç»„ï¼Œè®¿é—®åŸå¸‚çš„é¡ºåº
        save_path: GIFä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
        fps: å¸§ç‡ï¼ˆæ¯ç§’å¸§æ•°ï¼‰
    """
    # æå–åŸå¸‚åæ ‡
    if hasattr(td, 'get'):
        locs = td.get('locs', td['locs']).cpu().numpy()
    else:
        locs = td['locs'].cpu().numpy()
    
    num_cities = len(locs)
    frames = []
    
    # è®¡ç®—æ¯ä¸€æ­¥çš„ç´¯è®¡è·ç¦»
    def calculate_partial_distance(locs, actions, step):
        """è®¡ç®—åˆ°ç¬¬stepæ­¥ä¸ºæ­¢çš„ç´¯è®¡è·ç¦»"""
        if step < 1:
            return 0.0
        total_dist = 0.0
        for i in range(step):
            city_a = locs[actions[i]]
            # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œè¿”å›èµ·ç‚¹ï¼›å¦åˆ™ç»§ç»­ä¸‹ä¸€ä¸ªåŸå¸‚
            if i + 1 < len(actions):
                city_b = locs[actions[i + 1]]
            else:
                city_b = locs[actions[0]]  # è¿”å›èµ·ç‚¹
            dist = np.sqrt(np.sum((city_a - city_b) ** 2))
            total_dist += dist
        return total_dist
    
    # ä¸ºæ¯ä¸€æ­¥ç”Ÿæˆä¸€å¸§å›¾åƒ
    for step in range(num_cities + 1):
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # ç»˜åˆ¶æ‰€æœ‰åŸå¸‚ç‚¹
        ax.scatter(locs[:, 0], locs[:, 1], c='lightblue', s=200, 
                  zorder=3, alpha=0.6, edgecolors='black', linewidths=2)
        
        # æ ‡æ³¨åŸå¸‚ç¼–å·
        for i, (x, y) in enumerate(locs):
            ax.text(x, y, str(i), fontsize=10, ha='center', va='center',
                   fontweight='bold', color='darkblue')
        
        # ç»˜åˆ¶å·²ç»æ„å»ºçš„è·¯å¾„
        if step > 0:
            for i in range(step):
                start = locs[actions[i]]
                if i + 1 < len(actions):
                    end = locs[actions[i + 1]]
                else:
                    end = locs[actions[0]]  # æœ€åè¿”å›èµ·ç‚¹
                
                # ç»˜åˆ¶è·¯å¾„çº¿
                ax.plot([start[0], end[0]], [start[1], end[1]], 
                       'b-', linewidth=3, alpha=0.7, zorder=1)
                
                # æ·»åŠ ç®­å¤´è¡¨ç¤ºæ–¹å‘
                mid_x, mid_y = (start[0] + end[0]) / 2, (start[1] + end[1]) / 2
                dx, dy = end[0] - start[0], end[1] - start[1]
                ax.annotate('', xy=(mid_x + dx*0.1, mid_y + dy*0.1), 
                          xytext=(mid_x - dx*0.1, mid_y - dy*0.1),
                          arrowprops=dict(arrowstyle='->', color='blue', 
                                        lw=2, alpha=0.7))
        
        # é«˜äº®å½“å‰è®¿é—®çš„åŸå¸‚
        if step > 0 and step <= num_cities:
            current_city = actions[step - 1]
            ax.scatter(locs[current_city, 0], locs[current_city, 1], 
                      c='red', s=400, zorder=5, marker='*', 
                      edgecolors='darkred', linewidths=2,
                      label=f'å½“å‰: åŸå¸‚ {current_city}')
        
        # é«˜äº®èµ·ç‚¹
        start_city = actions[0]
        ax.scatter(locs[start_city, 0], locs[start_city, 1], 
                  c='green', s=300, zorder=4, marker='s',
                  edgecolors='darkgreen', linewidths=2,
                  label=f'èµ·ç‚¹: åŸå¸‚ {start_city}')
        
        # è®¡ç®—å½“å‰ç´¯è®¡æˆæœ¬
        current_cost = calculate_partial_distance(locs, actions, step)
        
        # è®¾ç½®æ ‡é¢˜å’Œä¿¡æ¯
        if step == 0:
            info_text = "å¼€å§‹æ„å»ºè·¯çº¿..."
        elif step < num_cities:
            info_text = f"ç¬¬ {step} æ­¥ | å·²è®¿é—® {step} ä¸ªåŸå¸‚ | ç´¯è®¡æˆæœ¬: {current_cost:.3f}"
        else:
            # æœ€åä¸€æ­¥ï¼Œè¿”å›èµ·ç‚¹
            final_dist = np.sqrt(np.sum((locs[actions[-1]] - locs[actions[0]]) ** 2))
            total_cost = current_cost + final_dist
            info_text = f"å®Œæˆï¼æ€»å…± {num_cities} ä¸ªåŸå¸‚ | æ€»æˆæœ¬: {total_cost:.3f}"
        
        ax.set_title(f"{title}\n{info_text}", fontsize=14, fontweight='bold', pad=20)
        
        # è®¾ç½®åæ ‡è½´
        ax.set_xlim(-0.05, 1.05)
        ax.set_ylim(-0.05, 1.05)
        ax.set_aspect('equal')
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.set_xlabel('X åæ ‡', fontsize=12)
        ax.set_ylabel('Y åæ ‡', fontsize=12)
        
        # æ·»åŠ å›¾ä¾‹
        if step > 0:
            ax.legend(loc='upper right', fontsize=10, framealpha=0.9)
        
        # æ·»åŠ è¿›åº¦æ¡
        progress = step / num_cities
        ax.text(0.5, -0.12, f"è¿›åº¦: {int(progress * 100)}%", 
               ha='center', va='top', transform=ax.transAxes,
               fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        # ä¿å­˜å½“å‰å¸§ä¸ºå›¾åƒ
        fig.tight_layout()
        
        # å°†å›¾å½¢è½¬æ¢ä¸ºPIL Imageï¼ˆå…¼å®¹æ–°æ—§ç‰ˆæœ¬matplotlibï¼‰
        fig.canvas.draw()
        try:
            # æ–°ç‰ˆæœ¬ matplotlib (>= 3.8)
            buf = fig.canvas.buffer_rgba()
            image = np.frombuffer(buf, dtype=np.uint8)
            image = image.reshape(fig.canvas.get_width_height()[::-1] + (4,))
            # è½¬æ¢ RGBA åˆ° RGB
            image = image[:, :, :3]
        except AttributeError:
            # æ—§ç‰ˆæœ¬ matplotlib
            try:
                image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')
                image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))
            except AttributeError:
                # æ›´è€çš„ç‰ˆæœ¬ï¼Œä½¿ç”¨ tostring_argb
                buf = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8)
                buf = buf.reshape(fig.canvas.get_width_height()[::-1] + (4,))
                # ARGB è½¬ RGB
                image = buf[:, :, 1:]
        
        frames.append(Image.fromarray(image))
        
        plt.close(fig)
    
    # åœ¨æœ€åä¸€å¸§åœç•™æ›´é•¿æ—¶é—´
    for _ in range(3):
        frames.append(frames[-1])
    
    # ä¿å­˜ä¸ºGIF
    duration = int(1000 / fps)  # æ¯å¸§æŒç»­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    frames[0].save(
        save_path,
        save_all=True,
        append_images=frames[1:],
        duration=duration,
        loop=0,
        optimize=False
    )

# ============================================
# ç”¨æˆ·è®¤è¯è·¯ç”±ï¼ˆæ–°å¢ï¼‰
# ============================================

@app.route('/')
def index():
    """ä¸»é¡µ - å¼ºåˆ¶ç™»å½•æ£€æŸ¥"""
    # æ¸…ç†å¯èƒ½çš„æ— æ•ˆsession
    user_id = get_current_user_id()
    
    # å¼ºåˆ¶æ£€æŸ¥ç”¨æˆ·æ˜¯å¦çœŸå®å­˜åœ¨
    if not user_id:
        # æ¸…é™¤å¯èƒ½æŸåçš„session
        session.clear()
        return redirect(url_for('login_page'))
    
    # éªŒè¯ç”¨æˆ·æ˜¯å¦åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
    user_manager = get_user_manager()
    if user_manager:
        user_info = user_manager.get_user(user_id)
        if not user_info:
            # ç”¨æˆ·ä¸å­˜åœ¨ï¼Œæ¸…é™¤sessionå¹¶é‡å®šå‘
            session.clear()
            return redirect(url_for('login_page'))
    
    username = get_current_username()
    return render_template('index.html', 
                         is_logged_in=True, 
                         username=username,
                         active_page='home')

@app.route('/login')
def login_page():
    """ç™»å½•é¡µé¢ - å¦‚æœå·²ç™»å½•åˆ™è·³è½¬åˆ°ä¸»é¡µ"""
    user_id = get_current_user_id()
    if user_id:
        # å·²ç™»å½•ï¼Œç›´æ¥è·³è½¬åˆ°ä¸»é¡µ
        return redirect(url_for('index'))
    return render_template('login.html')

@app.route('/register')
def register_page():
    """æ³¨å†Œé¡µé¢"""
    return render_template('register.html')

@app.route('/api/register', methods=['POST'])
def api_register():
    """ç”¨æˆ·æ³¨å†ŒAPI"""
    try:
        data = request.get_json()
        username = data.get('username')
        password = data.get('password')
        email = data.get('email')
        
        if not username or not password:
            return jsonify({
                'success': False, 
                'message': 'ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        user_manager = get_user_manager()
        if user_manager is None:
            return jsonify({
                'success': False,
                'message': 'è®¤è¯æ¨¡å—æœªåˆå§‹åŒ–'
            }), 500
        
        success, message, user_id = user_manager.create_user(username, password, email)
        
        if success:
            return jsonify({
                'success': True, 
                'message': message,
                'user_id': user_id
            })
        else:
            return jsonify({
                'success': False, 
                'message': message
            }), 400
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ³¨å†Œå¤±è´¥ï¼š{str(e)}'
        }), 500

@app.route('/api/login', methods=['POST'])
def api_login():
    """ç”¨æˆ·ç™»å½•API"""
    try:
        data = request.get_json()
        username = data.get('username')
        password = data.get('password')
        
        if not username or not password:
            return jsonify({
                'success': False, 
                'message': 'ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'
            }), 400
        
        user_manager = get_user_manager()
        if user_manager is None:
            return jsonify({
                'success': False,
                'message': 'è®¤è¯æ¨¡å—æœªåˆå§‹åŒ–'
            }), 500
        
        success, message, user_data = user_manager.verify_user(username, password)
        
        if success:
            set_user_session(user_data)
            return jsonify({
                'success': True, 
                'message': message,
                'user': user_data
            })
        else:
            return jsonify({
                'success': False, 
                'message': message
            }), 401
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'ç™»å½•å¤±è´¥ï¼š{str(e)}'
        }), 500

@app.route('/api/logout', methods=['POST'])
def api_logout():
    """ç”¨æˆ·ç™»å‡ºAPI"""
    clear_user_session()
    return jsonify({
        'success': True, 
        'message': 'å·²é€€å‡ºç™»å½•'
    })

@app.route('/logout')
def logout_page():
    """ç›´æ¥è®¿é—®çš„ç™»å‡ºé¡µé¢ - æ¸…é™¤sessionå¹¶è·³è½¬åˆ°ç™»å½•é¡µ"""
    session.clear()
    clear_user_session()
    return redirect(url_for('login_page'))

@app.route('/api/current_user', methods=['GET'])
def api_current_user():
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·ä¿¡æ¯"""
    user_id = get_current_user_id()
    if not user_id:
        return jsonify({
            'success': False, 
            'message': 'æœªç™»å½•'
        }), 401
    
    user_manager = get_user_manager()
    if user_manager is None:
        return jsonify({
            'success': False,
            'message': 'è®¤è¯æ¨¡å—æœªåˆå§‹åŒ–'
        }), 500
    
    user_data = user_manager.get_user(user_id)
    return jsonify({
        'success': True, 
        'user': user_data
    })

# ============================================
# åŸæœ‰è·¯ç”±ï¼ˆä¿æŒå…¼å®¹ï¼‰
# ============================================

@app.route('/res')
def Index_res():
    """æ—§ç‰ˆæ³¨å†Œé¡µé¢ - é‡å®šå‘åˆ°æ–°é¡µé¢"""
    return redirect(url_for('register_page'))

@app.route('/benchmark')
@login_required
def benchmark():
    """ç®—æ³•æ€§èƒ½å¯¹æ¯”é¡µé¢ - éœ€è¦ç™»å½•"""
    return render_template('benchmark.html', active_page='benchmark')

@app.route('/file_manager')
@login_required
def file_manager():
    """æ–‡ä»¶ç®¡ç†é¡µé¢ - éœ€è¦ç™»å½•"""
    return render_template('file_manager.html', active_page='file_manager')

@app.route('/profile')
@login_required
def profile():
    """æˆ‘çš„è´¦æˆ·é¡µé¢ - éœ€è¦ç™»å½•"""
    user_id = get_current_user_id()
    username = get_current_username()
    
    # è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
    user_data = {
        'username': username,
        'email': None,
        'create_time': None,
        'last_login': None
    }
    
    user_manager = get_user_manager()
    if user_manager:
        user_info = user_manager.get_user(user_id)
        if user_info:
            user_data['email'] = user_info.get('email')
            user_data['create_time'] = user_info.get('create_time').strftime('%Y-%m-%d %H:%M') if user_info.get('create_time') else None
            user_data['last_login'] = user_info.get('last_login').strftime('%Y-%m-%d %H:%M') if user_info.get('last_login') else None
    
    return render_template('profile.html', **user_data, active_page='profile')

@app.route('/api/user_stats', methods=['GET'])
@login_required
@cached_api(key_prefix='user_stats')
def get_user_stats():
    """è·å–ç”¨æˆ·ç»Ÿè®¡æ•°æ® - å®æ—¶æ•°æ®"""
    try:
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({'success': False, 'message': 'æœªç™»å½•'}), 401
        
        stats = {
            'total_sessions': 0,
            'completed_sessions': 0,
            'running_sessions': 0,
            'failed_sessions': 0,
            'total_files': 0,
            'total_size_mb': 0
        }
        
        # ä»æ•°æ®åº“è·å–ç»Ÿè®¡æ•°æ®
        db = get_db()
        session_manager = get_session_manager()
        file_manager = get_file_manager()
        
        if db and session_manager and file_manager:
            try:
                # è·å–è®­ç»ƒä¼šè¯ç»Ÿè®¡
                cursor = db.cursor(dictionary=True)
                cursor.execute("""
                    SELECT 
                        COUNT(*) as total,
                        SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,
                        SUM(CASE WHEN status = 'running' THEN 1 ELSE 0 END) as running,
                        SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed
                    FROM training_sessions
                    WHERE user_id = %s
                """, (user_id,))
                session_stats = cursor.fetchone()
                
                if session_stats:
                    stats['total_sessions'] = session_stats['total'] or 0
                    stats['completed_sessions'] = session_stats['completed'] or 0
                    stats['running_sessions'] = session_stats['running'] or 0
                    stats['failed_sessions'] = session_stats['failed'] or 0
                
                # è·å–æ–‡ä»¶ç»Ÿè®¡
                storage_stats = file_manager.get_user_storage_stats(user_id)
                if storage_stats:
                    stats['total_files'] = storage_stats['total_files'] or 0
                    stats['total_size_mb'] = storage_stats['total_mb'] or 0
                    
            except Exception as e:
                print(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}")
        
        return jsonify({
            'success': True,
            'stats': stats
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/user_activity', methods=['GET'])
@login_required
@cached_api(key_prefix='user_activity')
def get_user_activity():
    """è·å–ç”¨æˆ·æœ€è¿‘æ´»åŠ¨è®°å½• - å®æ—¶æ•°æ®"""
    try:
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({'success': False, 'message': 'æœªç™»å½•'}), 401
        
        activities = []
        
        # ä»æ•°æ®åº“è·å–æœ€è¿‘çš„è®­ç»ƒä¼šè¯
        db = get_db()
        session_manager = get_session_manager()
        
        if db and session_manager:
            try:
                cursor = db.cursor(dictionary=True)
                cursor.execute("""
                    SELECT 
                        session_id,
                        model_type,
                        problem_type,
                        status,
                        start_time,
                        end_time,
                        final_reward
                    FROM training_sessions
                    WHERE user_id = %s
                    ORDER BY start_time DESC
                    LIMIT 10
                """, (user_id,))
                
                sessions = cursor.fetchall()
                
                for session in sessions:
                    time_str = session['start_time'].strftime('%Y-%m-%d %H:%M')
                    
                    if session['status'] == 'completed':
                        text = f"å®Œæˆäº† {session['problem_type'].upper()} é—®é¢˜çš„è®­ç»ƒ ({session['model_type']})"
                        if session['final_reward']:
                            text += f" - å¥–åŠ±: {session['final_reward']:.2f}"
                    elif session['status'] == 'running':
                        text = f"å¼€å§‹è®­ç»ƒ {session['model_type']} æ¨¡å‹ ({session['problem_type'].upper()})"
                    elif session['status'] == 'failed':
                        text = f"è®­ç»ƒå¤±è´¥: {session['model_type']} ({session['problem_type'].upper()})"
                    else:
                        text = f"è®­ç»ƒ {session['model_type']} - {session['status']}"
                    
                    activities.append({
                        'time': time_str,
                        'text': text,
                        'status': session['status']
                    })
                    
            except Exception as e:
                print(f"è·å–æ´»åŠ¨è®°å½•å¤±è´¥: {str(e)}")
        
        # å¦‚æœæ²¡æœ‰æ´»åŠ¨è®°å½•ï¼Œè¿”å›æç¤º
        if not activities:
            activities = [{
                'time': 'æ— è®°å½•',
                'text': 'è¿˜æ²¡æœ‰è®­ç»ƒè®°å½•ï¼Œå¼€å§‹ä½ çš„ç¬¬ä¸€æ¬¡è®­ç»ƒå§ï¼',
                'status': 'info'
            }]
        
        return jsonify({
            'success': True,
            'activities': activities
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ´»åŠ¨è®°å½•å¤±è´¥: {str(e)}'
        }), 500

# æ¨¡å‹çŸ¥è¯†åº“æ•°æ®
MODEL_DATABASE = {
    "AM": {
        "name": "AM",
        "full_name": "Attention Model - æ³¨æ„åŠ›æ¨¡å‹",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2019",
        "paper_url": "https://arxiv.org/abs/1803.08475",
        "paper_venue": "ICLR 2019",
        "core_concept": """
            <p>Attention Model (AM) æ˜¯é¦–ä¸ªæˆåŠŸå°†Transformeræ¶æ„åº”ç”¨äºç»„åˆä¼˜åŒ–é—®é¢˜çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ã€‚å®ƒåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ•æ‰èŠ‚ç‚¹é—´çš„å…¨å±€ä¾èµ–å…³ç³»ï¼Œé€šè¿‡ç¼–ç å™¨-è§£ç å™¨ç»“æ„é€æ­¥æ„å»ºè§£å†³æ–¹æ¡ˆã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šå°†TSPç­‰è·¯ç”±é—®é¢˜è§†ä¸ºåºåˆ—åˆ°åºåˆ—(seq2seq)é—®é¢˜ï¼Œä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ èŠ‚ç‚¹çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­–ç•¥ç½‘ç»œã€‚
            </div>
        """,
        "architecture": """
            <h4>1. ç¼–ç å™¨ï¼ˆEncoderï¼‰</h4>
            <p>ä½¿ç”¨Transformerç¼–ç å™¨å¤„ç†è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ï¼Œç”ŸæˆèŠ‚ç‚¹çš„åµŒå…¥è¡¨ç¤ºï¼š</p>
            <ul>
                <li><strong>è¾“å…¥</strong>ï¼šèŠ‚ç‚¹åæ ‡ (x, y) æˆ–å…¶ä»–ç‰¹å¾</li>
                <li><strong>å¤šå¤´æ³¨æ„åŠ›</strong>ï¼šæ•æ‰èŠ‚ç‚¹é—´çš„å…¨å±€å…³ç³»</li>
                <li><strong>å‰é¦ˆç½‘ç»œ</strong>ï¼šæå–é«˜å±‚ç‰¹å¾</li>
                <li><strong>è¾“å‡º</strong>ï¼šèŠ‚ç‚¹åµŒå…¥å‘é‡</li>
            </ul>
            
            <h4>2. è§£ç å™¨ï¼ˆDecoderï¼‰</h4>
            <p>è‡ªå›å½’åœ°ç”Ÿæˆè®¿é—®åºåˆ—ï¼š</p>
            <ul>
                <li><strong>ä¸Šä¸‹æ–‡åµŒå…¥</strong>ï¼šèšåˆå·²è®¿é—®èŠ‚ç‚¹å’Œå½“å‰çŠ¶æ€</li>
                <li><strong>æ³¨æ„åŠ›è¯„åˆ†</strong>ï¼šè®¡ç®—æ¯ä¸ªå€™é€‰èŠ‚ç‚¹çš„é€‰æ‹©æ¦‚ç‡</li>
                <li><strong>åŠ¨ä½œæ©ç </strong>ï¼šç¡®ä¿ä¸é‡å¤è®¿é—®å·²é€‰èŠ‚ç‚¹</li>
                <li><strong>é‡‡æ ·/è´ªå¿ƒ</strong>ï¼šæ ¹æ®æ¦‚ç‡åˆ†å¸ƒé€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹</li>
            </ul>
            
            <h4>3. è®­ç»ƒç­–ç•¥</h4>
            <p>ä½¿ç”¨REINFORCEç®—æ³•è¿›è¡Œç­–ç•¥æ¢¯åº¦ä¼˜åŒ–ï¼š</p>
            <ul>
                <li><strong>Baseline</strong>ï¼šä½¿ç”¨è´ªå¿ƒrolloutæˆ–æŒ‡æ•°ç§»åŠ¨å¹³å‡é™ä½æ–¹å·®</li>
                <li><strong>Reward</strong>ï¼šè·¯å¾„æ€»é•¿åº¦çš„è´Ÿå€¼</li>
                <li><strong>æ¢¯åº¦ä¼°è®¡</strong>ï¼šé€šè¿‡é‡‡æ ·å¤šæ¡è·¯å¾„ä¼°è®¡ç­–ç•¥æ¢¯åº¦</li>
            </ul>
        """,
        "innovations": """
            <ul>
                <li>ğŸ”¹ <strong>Transformerç”¨äºCO</strong>ï¼šé¦–æ¬¡å°†TransformeræˆåŠŸåº”ç”¨äºç»„åˆä¼˜åŒ–</li>
                <li>ğŸ”¹ <strong>æ— éœ€ç›‘ç£æ•°æ®</strong>ï¼šçº¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä¸éœ€è¦æœ€ä¼˜è§£æ ‡ç­¾</li>
                <li>ğŸ”¹ <strong>é—®é¢˜æ— å…³æ¶æ„</strong>ï¼šå¯è½»æ¾é€‚é…TSPã€VRPç­‰å¤šç§é—®é¢˜</li>
                <li>ğŸ”¹ <strong>å¹¶è¡Œè®¡ç®—å‹å¥½</strong>ï¼šTransformerç»“æ„æ”¯æŒé«˜æ•ˆGPUå¹¶è¡Œ</li>
            </ul>
        """,
        "performance": """
            <div class="info-grid">
                <div class="info-card">
                    <h5>TSP-50</h5>
                    <p>Gap: 1.41%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>TSP-100</h5>
                    <p>Gap: 1.73%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>CVRP-50</h5>
                    <p>Gap: 5.30%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>CVRP-100</h5>
                    <p>Gap: 3.39%<br>Time: <1s</p>
                </div>
            </div>
            <p style="margin-top: 1rem;">åœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸‹ï¼ŒAMåœ¨TSP-50ä¸Šè¾¾åˆ°1.41%çš„Gapï¼Œé€Ÿåº¦æå¿«ä½†è´¨é‡ç•¥é€Šäºåç»­æ”¹è¿›æ–¹æ³•ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>æ¨ç†é€Ÿåº¦å¿«ï¼ˆ<1ç§’ï¼‰</li>
                <li>æ¶æ„ç®€æ´ï¼Œæ˜“äºç†è§£å’Œå®ç°</li>
                <li>å¯æ‰©å±•æ€§å¥½ï¼Œæ”¯æŒä¸åŒè§„æ¨¡é—®é¢˜</li>
                <li>æ³›åŒ–èƒ½åŠ›å¼ºï¼Œè®­ç»ƒè§„æ¨¡å¯è¿ç§»</li>
                <li>å¼€åˆ›æ€§å·¥ä½œï¼Œå½±å“åŠ›å¤§</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>å•æ¬¡è§£ç è´¨é‡æœ‰é™ï¼ˆGap~1-2%ï¼‰</li>
                <li>æœªå……åˆ†åˆ©ç”¨é—®é¢˜å¯¹ç§°æ€§</li>
                <li>è®­ç»ƒéœ€è¦å¤§é‡æ ·æœ¬</li>
                <li>å¯¹è¶…å‚æ•°è¾ƒæ•æ„Ÿ</li>
            </ul>
        """,
        "applications": """
            <p>é€‚ç”¨äºéœ€è¦å¿«é€Ÿæ±‚è§£çš„åœºæ™¯ï¼š</p>
            <ul>
                <li>å®æ—¶ç‰©æµè§„åˆ’</li>
                <li>åœ¨çº¿è·¯å¾„ä¼˜åŒ–</li>
                <li>å¤§è§„æ¨¡é—®é¢˜çš„å¿«é€Ÿè¿‘ä¼¼</li>
                <li>ä½œä¸ºå…¶ä»–æ–¹æ³•çš„baseline</li>
            </ul>
        """
    },
    "POMO": {
        "name": "POMO",
        "full_name": "Policy Optimization with Multiple Optima",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2021",
        "paper_url": "https://arxiv.org/abs/2010.16011",
        "paper_venue": "NeurIPS 2021",
        "core_concept": """
            <p>POMO é€šè¿‡ä»ä¸åŒèµ·ç‚¹åŒæ—¶æ„å»ºå¤šæ¡è·¯å¾„æ¥åˆ©ç”¨TSPç­‰é—®é¢˜çš„å¯¹ç§°æ€§ï¼Œæ˜¾è‘—æå‡äº†æ±‚è§£è´¨é‡è€Œä¸å¢åŠ æ¨¡å‹å¤æ‚åº¦ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ´å¯Ÿ</strong>ï¼šTSPé—®é¢˜å…·æœ‰æ—‹è½¬å¯¹ç§°æ€§ - ä»ä»»æ„èŠ‚ç‚¹å‡ºå‘éƒ½èƒ½å¾—åˆ°ç­‰ä»·çš„æœ€ä¼˜è§£ã€‚POMOåˆ©ç”¨è¿™ä¸€ç‰¹æ€§ï¼Œåœ¨è®­ç»ƒå’Œæ¨ç†æ—¶åŒæ—¶è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„èµ·ç‚¹ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. å¤šèµ·ç‚¹å¹¶è¡Œè§£ç </h4>
            <p>ä¸AMçš„å…³é”®åŒºåˆ«ï¼š</p>
            <ul>
                <li><strong>AM</strong>ï¼šå›ºå®šä»èŠ‚ç‚¹0å¼€å§‹</li>
                <li><strong>POMO</strong>ï¼šåŒæ—¶ä»æ‰€æœ‰Nä¸ªèŠ‚ç‚¹å¼€å§‹ï¼Œç”ŸæˆNæ¡è·¯å¾„</li>
            </ul>
            
            <h4>2. å¢å¼ºè®­ç»ƒç­–ç•¥</h4>
            <p>è®­ç»ƒæ—¶çš„ä¼˜åŠ¿ï¼š</p>
            <ul>
                <li>æ¯ä¸ªbatchå®é™…äº§ç”Ÿ NÃ—batch_size æ¡è·¯å¾„</li>
                <li>æ‰€æœ‰è·¯å¾„å…±äº«æ¢¯åº¦ï¼ŒåŠ é€Ÿå­¦ä¹ </li>
                <li>åˆ©ç”¨å¯¹ç§°æ€§ï¼Œå‡å°‘è®­ç»ƒæ–¹å·®</li>
            </ul>
            
            <h4>3. æ¨ç†æ—¶çš„ç­–ç•¥</h4>
            <ul>
                <li><strong>è®­ç»ƒæ¨¡å¼</strong>ï¼šä½¿ç”¨æ‰€æœ‰Nä¸ªèµ·ç‚¹çš„å¹³å‡æŸå¤±</li>
                <li><strong>æ¨ç†æ¨¡å¼</strong>ï¼šå–Næ¡è·¯å¾„ä¸­çš„æœ€ä¼˜è§£</li>
                <li><strong>å¢å¼ºç‰ˆæœ¬</strong>ï¼šå¯ç»“åˆæ•°æ®å¢å¼ºè¿›ä¸€æ­¥æå‡ï¼ˆ8Ã—Næ¡è·¯å¾„ï¼‰</li>
            </ul>
        """,
        "innovations": """
            <ul>
                <li>ğŸ”¹ <strong>å¯¹ç§°æ€§åˆ©ç”¨</strong>ï¼šå……åˆ†åˆ©ç”¨TSPçš„æ—‹è½¬ä¸å˜æ€§</li>
                <li>ğŸ”¹ <strong>è®­ç»ƒåŠ é€Ÿ</strong>ï¼šNå€æ•°æ®å¢å¼ºæ— é¢å¤–è®¡ç®—æˆæœ¬</li>
                <li>ğŸ”¹ <strong>æ¨ç†æå‡</strong>ï¼šNæ¡è·¯å¾„é€‰æœ€ä¼˜ï¼Œè´¨é‡æ˜¾è‘—æé«˜</li>
                <li>ğŸ”¹ <strong>æ— æ¶æ„ä¿®æ”¹</strong>ï¼šåŸºäºAMæ¶æ„ï¼Œæ— éœ€é‡æ–°è®¾è®¡</li>
            </ul>
        """,
        "performance": """
            <div class="info-grid">
                <div class="info-card">
                    <h5>TSP-50 (Greedy)</h5>
                    <p>Gap: 0.89%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>TSP-50 (Sampling)</h5>
                    <p>Gap: 0.18%<br>Time: 1m</p>
                </div>
                <div class="info-card">
                    <h5>TSP-100 (Greedy)</h5>
                    <p>Gap: 0.05%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>CVRP-50</h5>
                    <p>Gap: 3.99%<br>Time: <1s</p>
                </div>
            </div>
            <p style="margin-top: 1rem;"><strong>æ˜¾è‘—ä¼˜äºAM</strong>ï¼šåœ¨TSP-50ä¸Šä»1.41%é™è‡³0.89%ï¼Œæ¥è¿‘50%çš„è´¨é‡æå‡ï¼</p>
        """,
        "advantages": """
            <ul>
                <li>è´¨é‡å¤§å¹…æå‡ï¼ˆAMçš„1.5-2å€ï¼‰</li>
                <li>è®­ç»ƒé€Ÿåº¦å¿«ï¼ˆæ•°æ®åˆ©ç”¨ç‡é«˜ï¼‰</li>
                <li>æ¨ç†ä»ç„¶å¾ˆå¿«ï¼ˆ<1ç§’ï¼‰</li>
                <li>å®ç°ç®€å•ï¼ŒåŸºäºAMå°æ”¹</li>
                <li>é€‚ç”¨äºæ‰€æœ‰å¯¹ç§°æ€§é—®é¢˜</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>ä»…é€‚ç”¨äºå…·æœ‰å¯¹ç§°æ€§çš„é—®é¢˜</li>
                <li>GPUå†…å­˜å ç”¨å¢åŠ Nå€</li>
                <li>å¯¹éå¯¹ç§°é—®é¢˜æ— ä¼˜åŠ¿</li>
                <li>æå¤§è§„æ¨¡é—®é¢˜å†…å­˜å‹åŠ›å¤§</li>
            </ul>
        """,
        "applications": """
            <p>POMOç‰¹åˆ«é€‚åˆï¼š</p>
            <ul>
                <li>TSPåŠå…¶å˜ä½“ï¼ˆå¯¹ç§°æ€§å¼ºï¼‰</li>
                <li>CVRPç­‰è½¦è¾†è·¯å¾„é—®é¢˜</li>
                <li>éœ€è¦é«˜è´¨é‡è§£çš„å®æ—¶åº”ç”¨</li>
                <li>GPUèµ„æºå……è¶³çš„åœºæ™¯</li>
            </ul>
        """
    },
    "SymNCO": {
        "name": "Sym-NCO",
        "full_name": "Symmetric Neural Combinatorial Optimization",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2022",
        "paper_url": "https://arxiv.org/abs/2205.13209",
        "paper_venue": "NeurIPS 2022",
        "core_concept": """
            <p>Sym-NCO å°†å¯¹ç§°æ€§çš„åˆ©ç”¨ä»æ¨ç†æ‰©å±•åˆ°æ•´ä¸ªç½‘ç»œæ¶æ„ï¼Œé€šè¿‡è®¾è®¡ç­‰å˜ç¥ç»ç½‘ç»œæ¥å¼ºåˆ¶æ¨¡å‹å­¦ä¹ é—®é¢˜çš„å†…åœ¨å¯¹ç§°ç»“æ„ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒåˆ›æ–°</strong>ï¼šä¸ä»…åƒPOMOé‚£æ ·åœ¨æ•°æ®å±‚é¢åˆ©ç”¨å¯¹ç§°æ€§ï¼Œè€Œæ˜¯åœ¨ç½‘ç»œå±‚é¢åµŒå…¥å¯¹ç§°æ€§çº¦æŸï¼Œä½¿æ¨¡å‹ä»æ ¹æœ¬ä¸Šå­¦ä¹ åˆ°æ—‹è½¬ã€ç¿»è½¬ç­‰å¯¹ç§°ä¸å˜çš„ç‰¹å¾ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. ç­‰å˜ç½‘ç»œè®¾è®¡</h4>
            <p>å…³é”®æ¶æ„ç‰¹ç‚¹ï¼š</p>
            <ul>
                <li><strong>ç­‰å˜ç¼–ç å™¨</strong>ï¼šå¯¹è¾“å…¥çš„æ—‹è½¬/ç¿»è½¬å˜æ¢ï¼Œè¾“å‡ºä¹Ÿç›¸åº”å˜æ¢</li>
                <li><strong>ä¸å˜ç‰¹å¾</strong>ï¼šæå–å¯¹ç§°ä¸å˜çš„å…¨å±€ç‰¹å¾</li>
                <li><strong>æ¡ä»¶è§£ç </strong>ï¼šåŸºäºä¸å˜ç‰¹å¾çš„æ¡ä»¶ç”Ÿæˆ</li>
            </ul>
            
            <h4>2. å¯¹ç§°æ€§åˆ†ç±»</h4>
            <p>Sym-NCOåŒºåˆ†å¹¶åˆ©ç”¨ä¸‰ç±»å¯¹ç§°æ€§ï¼š</p>
            <ul>
                <li><strong>æ—‹è½¬å¯¹ç§°</strong>ï¼šä»»æ„èŠ‚ç‚¹å¯ä½œä¸ºèµ·ç‚¹</li>
                <li><strong>ç¿»è½¬å¯¹ç§°</strong>ï¼šé¡ºæ—¶é’ˆ/é€†æ—¶é’ˆè·¯å¾„ç­‰ä»·</li>
                <li><strong>æ’åˆ—å¯¹ç§°</strong>ï¼šèŠ‚ç‚¹æ ‡ç­¾å¯ä»»æ„æ’åˆ—</li>
            </ul>
            
            <h4>3. è®­ç»ƒä¼˜åŒ–</h4>
            <ul>
                <li>å¯¹ç§°å¢å¼ºçš„æ•°æ®ç”Ÿæˆ</li>
                <li>ç­‰å˜æ€§æŸå¤±çº¦æŸ</li>
                <li>å¤šèµ·ç‚¹è”åˆè®­ç»ƒ</li>
            </ul>
        """,
        "innovations": """
            <ul>
                <li>ğŸ”¹ <strong>ç­‰å˜ç½‘ç»œæ¶æ„</strong>ï¼šä»ç½‘ç»œå±‚é¢ä¿è¯å¯¹ç§°æ€§</li>
                <li>ğŸ”¹ <strong>ç†è®ºä¿è¯</strong>ï¼šä¸¥æ ¼çš„æ•°å­¦å¯¹ç§°æ€§çº¦æŸ</li>
                <li>ğŸ”¹ <strong>æ³›åŒ–èƒ½åŠ›</strong>ï¼šæ›´å¥½çš„åˆ†å¸ƒå¤–æ³›åŒ–</li>
                <li>ğŸ”¹ <strong>å‚æ•°æ•ˆç‡</strong>ï¼šé€šè¿‡å¯¹ç§°æ€§å‡å°‘éœ€è¦å­¦ä¹ çš„å‚æ•°</li>
            </ul>
        """,
        "performance": """
            <div class="info-grid">
                <div class="info-card">
                    <h5>TSP-50 (Greedy)</h5>
                    <p>Gap: 0.47%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>TSP-50 (Aug)</h5>
                    <p>Gap: 0.01%<br>Time: 1m</p>
                </div>
                <div class="info-card">
                    <h5>TSP-20</h5>
                    <p>Gap: 0.05%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>CVRP-50</h5>
                    <p>Gap: 4.61%<br>Time: <1s</p>
                </div>
            </div>
            <p style="margin-top: 1rem;"><strong>ç›®å‰æœ€ä¼˜</strong>ï¼šåœ¨TSP-50ä¸Šè¾¾åˆ°0.47% Gapï¼ˆGreedyï¼‰ï¼Œä½¿ç”¨æ•°æ®å¢å¼ºåä»…0.01%ï¼Œå‡ ä¹æœ€ä¼˜ï¼</p>
        """,
        "advantages": """
            <ul>
                <li>è´¨é‡æœ€ä¼˜ï¼ˆå½“å‰SOTAä¹‹ä¸€ï¼‰</li>
                <li>ç†è®ºåŸºç¡€æ‰å®</li>
                <li>æ³›åŒ–èƒ½åŠ›å¼º</li>
                <li>å‚æ•°æ•ˆç‡é«˜</li>
                <li>è®­ç»ƒç¨³å®šæ€§å¥½</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>å®ç°å¤æ‚åº¦é«˜</li>
                <li>éœ€è¦æ·±å…¥ç†è§£ç¾¤è®º</li>
                <li>è®¡ç®—å¼€é”€ç•¥é«˜äºAM/POMO</li>
                <li>å¯¹éå¯¹ç§°é—®é¢˜é€‚ç”¨æ€§æœ‰é™</li>
            </ul>
        """,
        "applications": """
            <p>Sym-NCOæœ€é€‚åˆï¼š</p>
            <ul>
                <li>å¯¹è§£è´¨é‡è¦æ±‚æé«˜çš„åœºæ™¯</li>
                <li>éœ€è¦åˆ†å¸ƒå¤–æ³›åŒ–çš„åº”ç”¨</li>
                <li>å­¦æœ¯ç ”ç©¶å’Œæ–¹æ³•å¯¹æ¯”</li>
                <li>å¯¹ç§°æ€§å¼ºçš„COé—®é¢˜</li>
            </ul>
        """
    },
    "REINFORCE": {
        "name": "REINFORCE",
        "full_name": "REINFORCE Algorithm",
        "category": "å¼ºåŒ–å­¦ä¹ ç®—æ³•",
        "year": "1992",
        "paper_url": "https://link.springer.com/article/10.1007/BF00992696",
        "paper_venue": "Machine Learning 1992",
        "core_concept": """
            <p>REINFORCE æ˜¯æœ€ç»å…¸çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œç›´æ¥ä¼˜åŒ–ç­–ç•¥ç½‘ç»œçš„å‚æ•°ä»¥æœ€å¤§åŒ–æœŸæœ›å›æŠ¥ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šé€šè¿‡è’™ç‰¹å¡æ´›é‡‡æ ·ä¼°è®¡ç­–ç•¥æ¢¯åº¦ï¼Œæ ¹æ®å®é™…è·å¾—çš„å›æŠ¥è°ƒæ•´ç­–ç•¥ï¼Œä½¿å¥½çš„åŠ¨ä½œæ›´å¯èƒ½è¢«é€‰æ‹©ã€‚
            </div>
        """,
        "architecture": """
            <h4>ç®—æ³•æµç¨‹</h4>
            <ol>
                <li><strong>é‡‡æ ·</strong>ï¼šæ ¹æ®å½“å‰ç­–ç•¥Ï€ç”Ÿæˆå®Œæ•´çš„è½¨è¿¹</li>
                <li><strong>è®¡ç®—å›æŠ¥</strong>ï¼šR = -è·¯å¾„é•¿åº¦ï¼ˆTSPæƒ…å†µï¼‰</li>
                <li><strong>è®¡ç®—æ¢¯åº¦</strong>ï¼šâˆ‡J = E[âˆ‡log Ï€(a|s) Â· (R - b)]</li>
                <li><strong>æ›´æ–°å‚æ•°</strong>ï¼šÎ¸ â† Î¸ + Î±âˆ‡J</li>
            </ol>
            
            <h4>BaselineæŠ€å·§</h4>
            <p>ä¸ºé™ä½æ¢¯åº¦æ–¹å·®ï¼Œä½¿ç”¨baseline bï¼š</p>
            <ul>
                <li><strong>ç§»åŠ¨å¹³å‡</strong>ï¼šb = EMA(R)</li>
                <li><strong>Criticç½‘ç»œ</strong>ï¼šb = V(s)</li>
                <li><strong>Greedy rollout</strong>ï¼šb = è´ªå¿ƒè§£çš„å›æŠ¥</li>
            </ul>
        """,
        "performance": """
            <p>REINFORCEæœ¬èº«æ˜¯è®­ç»ƒç®—æ³•ï¼Œä¸æ˜¯æ¨¡å‹æ¶æ„ã€‚å®ƒè¢«ç”¨äºè®­ç»ƒAMã€POMOç­‰æ¨¡å‹ã€‚</p>
            <p>é…åˆAMä½¿ç”¨æ—¶çš„æ€§èƒ½å‚è€ƒAMçš„æ•°æ®ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>ç®€å•ç›´è§‚ï¼Œæ˜“äºå®ç°</li>
                <li>é€‚ç”¨äºä»»æ„ç­–ç•¥ç½‘ç»œ</li>
                <li>æ— éœ€å€¼å‡½æ•°è¿‘ä¼¼</li>
                <li>é€‚åˆé«˜ç»´ç¦»æ•£åŠ¨ä½œç©ºé—´</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>æ¢¯åº¦æ–¹å·®å¤§</li>
                <li>æ ·æœ¬æ•ˆç‡ä½</li>
                <li>è®­ç»ƒä¸ç¨³å®š</li>
                <li>éœ€è¦å¤§é‡episode</li>
            </ul>
        """
    },
    "DeepACO": {
        "name": "DeepACO",
        "full_name": "Deep Ant Colony Optimization",
        "category": "æ„é€ æ–¹æ³•ï¼ˆéè‡ªå›å½’ï¼‰",
        "year": "2023",
        "paper_url": "https://arxiv.org/abs/2309.14032",
        "paper_venue": "NeurIPS 2023",
        "core_concept": """
            <p>DeepACO å°†ç»å…¸çš„èšç¾¤ä¼˜åŒ–ç®—æ³•ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ å¯å‘å¼ä¿¡æ¯ï¼ŒæŒ‡å¯¼èšç¾¤çš„è·¯å¾„æœç´¢ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒåˆ›æ–°</strong>ï¼šç”¨ç¥ç»ç½‘ç»œæ›¿ä»£ä¼ ç»ŸACOçš„å¯å‘å¼å‡½æ•°ï¼Œä½¿ç®—æ³•èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ é—®é¢˜ç‰¹å®šçš„æœç´¢ç­–ç•¥ï¼Œå…¼å…·ACOçš„å…¨å±€æœç´¢èƒ½åŠ›å’Œæ·±åº¦å­¦ä¹ çš„è¡¨å¾èƒ½åŠ›ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. ç¥ç»ç½‘ç»œå¯å‘å¼</h4>
            <ul>
                <li>ä½¿ç”¨GNNå­¦ä¹ è¾¹çš„å¯å‘å¼å€¼</li>
                <li>æ›¿ä»£ä¼ ç»Ÿçš„è·ç¦»å€’æ•°å¯å‘å¼</li>
                <li>èƒ½å¤Ÿæ•æ‰å¤æ‚çš„é—®é¢˜ç»“æ„</li>
            </ul>
            
            <h4>2. èšç¾¤æœç´¢</h4>
            <ul>
                <li>å¤šåªèš‚èšå¹¶è¡Œæ„å»ºè§£</li>
                <li>ä¿¡æ¯ç´ æ›´æ–°æœºåˆ¶</li>
                <li>å±€éƒ¨æœç´¢ä¼˜åŒ–</li>
            </ul>
            
            <h4>3. éè‡ªå›å½’ç‰¹æ€§</h4>
            <ul>
                <li>æ‰€æœ‰èš‚èšåŒæ—¶æ„å»ºè§£</li>
                <li>å¹¶è¡Œåº¦é«˜ï¼Œé€Ÿåº¦å¿«</li>
                <li>é€‚åˆå¤§è§„æ¨¡é—®é¢˜</li>
            </ul>
        """,
        "performance": """
            <p>DeepACOåœ¨TSPä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡å®ä¾‹ä¸Šã€‚</p>
            <div class="info-card">
                <h5>ç‰¹ç‚¹</h5>
                <p>â€¢ è´¨é‡é«˜ï¼ˆæ¥è¿‘æœ€ä¼˜ï¼‰<br>â€¢ å¤§è§„æ¨¡é—®é¢˜ä¼˜åŠ¿æ˜æ˜¾<br>â€¢ å¯è§£é‡Šæ€§å¼º</p>
            </div>
        """,
        "advantages": """
            <ul>
                <li>è§£è´¨é‡é«˜</li>
                <li>å¯è§£é‡Šæ€§å¼ºï¼ˆåŸºäºACOï¼‰</li>
                <li>å¤§è§„æ¨¡é—®é¢˜è¡¨ç°å¥½</li>
                <li>ç»“åˆæ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿä¼˜åŒ–</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>æ¨ç†æ—¶é—´è¾ƒé•¿</li>
                <li>éœ€è¦å¤šæ¬¡è¿­ä»£</li>
                <li>å®ç°å¤æ‚</li>
                <li>è¶…å‚æ•°è¾ƒå¤š</li>
            </ul>
        """
    },
    "MatNet": {
        "name": "MatNet",
        "full_name": "Matrix Network - çŸ©é˜µç½‘ç»œ",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2021",
        "paper_url": "https://arxiv.org/abs/2106.11113",
        "paper_venue": "NeurIPS 2021",
        "core_concept": """
            <p>MatNet é€šè¿‡ç›´æ¥å»ºæ¨¡èŠ‚ç‚¹å¯¹ä¹‹é—´çš„å…³ç³»çŸ©é˜µï¼Œå®ç°äº†æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›å’Œæ›´å¥½çš„æ€§èƒ½ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šä¼ ç»Ÿæ–¹æ³•å¯¹æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹ç¼–ç ï¼Œè€ŒMatNetä½¿ç”¨çŸ©é˜µè¡¨ç¤ºèŠ‚ç‚¹å¯¹ä¹‹é—´çš„å…³ç³»ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å›¾ç»“æ„ä¿¡æ¯ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. çŸ©é˜µç¼–ç å™¨</h4>
            <ul>
                <li>æ„å»ºèŠ‚ç‚¹å¯¹å…³ç³»çŸ©é˜µ</li>
                <li>ä½¿ç”¨çŸ©é˜µæ³¨æ„åŠ›æœºåˆ¶</li>
                <li>æ•æ‰é«˜é˜¶ç»“æ„ä¿¡æ¯</li>
            </ul>
            
            <h4>2. è§£ç ç­–ç•¥</h4>
            <ul>
                <li>åŸºäºçŸ©é˜µè¡¨ç¤ºçš„åŠ¨ä½œé€‰æ‹©</li>
                <li>è€ƒè™‘å·²é€‰è·¯å¾„çš„å…¨å±€ä¿¡æ¯</li>
                <li>åŠ¨æ€æ›´æ–°å…³ç³»çŸ©é˜µ</li>
            </ul>
        """,
        "performance": """
            <p>MatNetåœ¨TSPå’ŒVRPé—®é¢˜ä¸Šéƒ½è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡é—®é¢˜ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>è¡¨è¾¾èƒ½åŠ›å¼º</li>
                <li>æ€§èƒ½ä¼˜å¼‚</li>
                <li>é€‚ç”¨äºå¤šç§é—®é¢˜</li>
                <li>å¯¹å›¾ç»“æ„å»ºæ¨¡å……åˆ†</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è®¡ç®—å¤æ‚åº¦é«˜ï¼ˆO(nÂ²)ï¼‰</li>
                <li>å†…å­˜å ç”¨å¤§</li>
                <li>è®­ç»ƒæ—¶é—´è¾ƒé•¿</li>
                <li>å®ç°å¤æ‚</li>
            </ul>
        """
    },
    "A2C": {
        "name": "A2C",
        "full_name": "Advantage Actor-Critic",
        "category": "å¼ºåŒ–å­¦ä¹ ç®—æ³•",
        "year": "2016",
        "paper_url": "https://arxiv.org/abs/1602.01783",
        "paper_venue": "ICML 2016",
        "core_concept": """
            <p>A2C æ˜¯Actor-Criticç®—æ³•çš„åŒæ­¥ç‰ˆæœ¬ï¼ŒåŒæ—¶å­¦ä¹ ç­–ç•¥ç½‘ç»œï¼ˆActorï¼‰å’Œä»·å€¼ç½‘ç»œï¼ˆCriticï¼‰ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šä½¿ç”¨Criticç½‘ç»œä¼°è®¡çŠ¶æ€ä»·å€¼ï¼Œä¸ºActoræä¾›æ›´ç¨³å®šçš„è®­ç»ƒä¿¡å·ï¼Œå‡å°‘REINFORCEçš„æ–¹å·®é—®é¢˜ã€‚
            </div>
        """,
        "architecture": """
            <h4>ç®—æ³•ç»„æˆ</h4>
            <ul>
                <li><strong>Actor</strong>ï¼šç­–ç•¥ç½‘ç»œÏ€(a|s)</li>
                <li><strong>Critic</strong>ï¼šä»·å€¼ç½‘ç»œV(s)</li>
                <li><strong>Advantage</strong>ï¼šA(s,a) = R - V(s)</li>
            </ul>
            
            <h4>è®­ç»ƒæµç¨‹</h4>
            <ol>
                <li>Actorç”ŸæˆåŠ¨ä½œå¹¶æ‰§è¡Œ</li>
                <li>Criticè¯„ä¼°çŠ¶æ€ä»·å€¼</li>
                <li>è®¡ç®—ä¼˜åŠ¿å‡½æ•°</li>
                <li>åŒæ—¶æ›´æ–°Actorå’ŒCritic</li>
            </ol>
        """,
        "performance": """
            <p>A2Cåœ¨è®­ç»ƒç¨³å®šæ€§å’Œæ ·æœ¬æ•ˆç‡ä¸Šä¼˜äºREINFORCEã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>è®­ç»ƒæ›´ç¨³å®š</li>
                <li>æ–¹å·®æ›´å°</li>
                <li>æ”¶æ•›æ›´å¿«</li>
                <li>æ ·æœ¬æ•ˆç‡é«˜</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>éœ€è¦é¢å¤–çš„Criticç½‘ç»œ</li>
                <li>å®ç°å¤æ‚åº¦å¢åŠ </li>
                <li>è¶…å‚æ•°æ›´å¤š</li>
                <li>å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜</li>
            </ul>
        """
    },
    "PPO": {
        "name": "PPO",
        "full_name": "Proximal Policy Optimization",
        "category": "å¼ºåŒ–å­¦ä¹ ç®—æ³•",
        "year": "2017",
        "paper_url": "https://arxiv.org/abs/1707.06347",
        "paper_venue": "ArXiv 2017",
        "core_concept": """
            <p>PPO é€šè¿‡é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦æ¥å¹³è¡¡æ¢ç´¢ä¸å¼€å‘ï¼Œæ˜¯ç›®å‰æœ€æµè¡Œçš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ä¹‹ä¸€ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šä½¿ç”¨è£å‰ªç›®æ ‡å‡½æ•°ï¼Œé˜²æ­¢ç­–ç•¥æ›´æ–°æ­¥é•¿è¿‡å¤§ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§ã€‚
            </div>
        """,
        "architecture": """
            <h4>PPO-Clipç›®æ ‡</h4>
            <p>L(Î¸) = E[min(r(Î¸)A, clip(r(Î¸), 1-Îµ, 1+Îµ)A)]</p>
            <ul>
                <li><strong>r(Î¸)</strong>ï¼šæ–°æ—§ç­–ç•¥çš„æ¦‚ç‡æ¯”</li>
                <li><strong>clip</strong>ï¼šé™åˆ¶åœ¨[1-Îµ, 1+Îµ]èŒƒå›´å†…</li>
                <li><strong>A</strong>ï¼šä¼˜åŠ¿å‡½æ•°</li>
            </ul>
            
            <h4>è®­ç»ƒç‰¹ç‚¹</h4>
            <ul>
                <li>å¤šæ¬¡åˆ©ç”¨åŒä¸€æ‰¹æ•°æ®</li>
                <li>è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ ç‡</li>
                <li>ç¨³å®šçš„ç­–ç•¥æ”¹è¿›</li>
            </ul>
        """,
        "performance": """
            <p>PPOåœ¨å„ç§RLä»»åŠ¡ä¸Šéƒ½è¡¨ç°ä¼˜å¼‚ï¼Œè¢«è®¤ä¸ºæ˜¯æœ€å¯é çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>è®­ç»ƒæå…¶ç¨³å®š</li>
                <li>æ ·æœ¬æ•ˆç‡é«˜</li>
                <li>è¶…å‚æ•°ä¸æ•æ„Ÿ</li>
                <li>å®ç°ç›¸å¯¹ç®€å•</li>
                <li>å·¥ä¸šç•Œå¹¿æ³›ä½¿ç”¨</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è®¡ç®—å¼€é”€è¾ƒå¤§</li>
                <li>éœ€è¦å¤šæ¬¡è¿­ä»£</li>
                <li>å¢™é’Ÿæ—¶é—´è¾ƒé•¿</li>
            </ul>
        """
    },
    "PtrNet": {
        "name": "PtrNet",
        "full_name": "Pointer Network - æŒ‡é’ˆç½‘ç»œ",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2015",
        "paper_url": "https://arxiv.org/abs/1506.03134",
        "paper_venue": "NeurIPS 2015",
        "core_concept": """
            <p>Pointer Network æ˜¯æœ€æ—©å°†seq2seqæ¨¡å‹åº”ç”¨äºç»„åˆä¼˜åŒ–çš„å¼€åˆ›æ€§å·¥ä½œã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒåˆ›æ–°</strong>ï¼šè¾“å‡ºå±‚ä¸æ˜¯å›ºå®šè¯è¡¨ï¼Œè€Œæ˜¯"æŒ‡å‘"è¾“å…¥åºåˆ—ä¸­çš„å…ƒç´ ï¼Œå¤©ç„¶é€‚åˆTSPç­‰æ’åˆ—é—®é¢˜ã€‚
            </div>
        """,
        "architecture": """
            <h4>æ¶æ„ç‰¹ç‚¹</h4>
            <ul>
                <li>LSTMç¼–ç å™¨å¤„ç†è¾“å…¥</li>
                <li>æ³¨æ„åŠ›æœºåˆ¶æŒ‡å‘è¾“å…¥èŠ‚ç‚¹</li>
                <li>è‡ªå›å½’ç”Ÿæˆè®¿é—®åºåˆ—</li>
            </ul>
        """,
        "performance": """
            <p>ä½œä¸ºæ—©æœŸå·¥ä½œï¼Œæ€§èƒ½ä¸å¦‚ç°ä»£Transformer basedæ–¹æ³•ï¼Œä½†å…·æœ‰é‡è¦çš„å†å²æ„ä¹‰ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>å¼€åˆ›æ€§å·¥ä½œ</li>
                <li>æ¦‚å¿µç®€æ´æ¸…æ™°</li>
                <li>æ˜“äºç†è§£</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>LSTMåºåˆ—åŒ–å¤„ç†æ…¢</li>
                <li>æ€§èƒ½ä¸å¦‚ç°ä»£æ–¹æ³•</li>
                <li>éš¾ä»¥å¹¶è¡ŒåŒ–</li>
            </ul>
        """
    },
    "HAM": {
        "name": "HAM",
        "full_name": "Hierarchical Attention Model",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2020",
        "paper_url": "https://arxiv.org/abs/2011.03227",
        "paper_venue": "AAAI 2021",
        "core_concept": """
            <p>HAM å¼•å…¥å±‚æ¬¡åŒ–æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ä¸åŒç²’åº¦ä¸Šæ•æ‰é—®é¢˜ç»“æ„ï¼Œé€šè¿‡å…¨å±€å’Œå±€éƒ¨ä¸¤ä¸ªå±‚æ¬¡çš„æ³¨æ„åŠ›å®ç°æ›´ç²¾ç»†çš„èŠ‚ç‚¹ç‰¹å¾å»ºæ¨¡ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒåˆ›æ–°</strong>ï¼šä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨å•ä¸€å°ºåº¦çš„æ³¨æ„åŠ›ï¼ŒHAMé€šè¿‡å±‚æ¬¡åŒ–è®¾è®¡åŒæ—¶æ•æ‰å…¨å±€ç»“æ„ä¿¡æ¯å’Œå±€éƒ¨é‚»åŸŸå…³ç³»ï¼Œæå‡äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. å…¨å±€æ³¨æ„åŠ›å±‚</h4>
            <ul>
                <li><strong>ä½œç”¨èŒƒå›´</strong>ï¼šè€ƒè™‘æ‰€æœ‰èŠ‚ç‚¹çš„å…³ç³»</li>
                <li><strong>åŠŸèƒ½</strong>ï¼šæ•æ‰é—®é¢˜çš„æ•´ä½“ç»“æ„å’Œè¿œè·ç¦»ä¾èµ–</li>
                <li><strong>å®ç°</strong>ï¼šMulti-head Transformer Attention</li>
            </ul>
            
            <h4>2. å±€éƒ¨æ³¨æ„åŠ›å±‚</h4>
            <ul>
                <li><strong>ä½œç”¨èŒƒå›´</strong>ï¼šå…³æ³¨ç©ºé—´ä¸Šç›¸è¿‘çš„èŠ‚ç‚¹</li>
                <li><strong>åŠŸèƒ½</strong>ï¼šæå–å±€éƒ¨åŒºåŸŸçš„ç»†ç²’åº¦ç‰¹å¾</li>
                <li><strong>å®ç°</strong>ï¼šåŸºäºè·ç¦»çš„å—é™æ³¨æ„åŠ›æœºåˆ¶</li>
            </ul>
            
            <h4>3. å±‚æ¬¡åŒ–èåˆ</h4>
            <ul>
                <li>é—¨æ§æœºåˆ¶åŠ¨æ€å¹³è¡¡å…¨å±€å’Œå±€éƒ¨ç‰¹å¾</li>
                <li>è‡ªé€‚åº”æƒé‡åˆ†é…</li>
                <li>æ®‹å·®è¿æ¥ä¿è¯æ¢¯åº¦æµåŠ¨</li>
            </ul>
            
            <h4>4. è§£ç ç­–ç•¥</h4>
            <ul>
                <li>åŸºäºèåˆç‰¹å¾çš„è‡ªå›å½’è§£ç </li>
                <li>åŠ¨æ€ä¸Šä¸‹æ–‡æ›´æ–°</li>
                <li>Masked attentioné˜²æ­¢é‡å¤è®¿é—®</li>
            </ul>
        """,
        "innovations": """
            <ul>
                <li>ğŸ”¹ <strong>åŒå±‚æ³¨æ„åŠ›</strong>ï¼šå…¨å±€+å±€éƒ¨çš„å±‚æ¬¡åŒ–è®¾è®¡</li>
                <li>ğŸ”¹ <strong>è‡ªé€‚åº”èåˆ</strong>ï¼šé—¨æ§æœºåˆ¶åŠ¨æ€å¹³è¡¡ä¸åŒå°ºåº¦</li>
                <li>ğŸ”¹ <strong>è®¡ç®—æ•ˆç‡</strong>ï¼šå±€éƒ¨æ³¨æ„åŠ›é™ä½å¤æ‚åº¦</li>
                <li>ğŸ”¹ <strong>æ³›åŒ–èƒ½åŠ›</strong>ï¼šå¤šå°ºåº¦ç‰¹å¾å¢å¼ºé²æ£’æ€§</li>
            </ul>
        """,
        "performance": """
            <div class="info-grid">
                <div class="info-card">
                    <h5>TSP-50</h5>
                    <p>Gap: 1.15%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>TSP-100</h5>
                    <p>Gap: 1.52%<br>Time: 1s</p>
                </div>
                <div class="info-card">
                    <h5>CVRP-100</h5>
                    <p>Gap: 4.89%<br>Time: 2s</p>
                </div>
            </div>
            <p style="margin-top: 1rem;">HAMåœ¨å•æ¬¡è§£ç è´¨é‡ä¸Šä¼˜äºåŸºç¡€AMï¼Œä½†ç•¥é€ŠäºPOMOå’ŒSym-NCOã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>å¤šå°ºåº¦ç‰¹å¾å»ºæ¨¡èƒ½åŠ›å¼º</li>
                <li>æ€§èƒ½ä¼˜äºåŸºç¡€AM</li>
                <li>å¯¹å¤æ‚ç»“æ„é—®é¢˜è¡¨ç°å¥½</li>
                <li>å±€éƒ¨æ³¨æ„åŠ›é™ä½äº†è®¡ç®—å¤æ‚åº¦</li>
                <li>æ³›åŒ–èƒ½åŠ›è¾ƒå¼º</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>å®ç°å¤æ‚åº¦é«˜äºAM</li>
                <li>è®­ç»ƒéš¾åº¦å¢åŠ </li>
                <li>è¶…å‚æ•°è°ƒä¼˜è¾ƒæ•æ„Ÿ</li>
                <li>å†…å­˜å ç”¨ç•¥é«˜</li>
            </ul>
        """,
        "applications": """
            <p>HAMé€‚ç”¨äºï¼š</p>
            <ul>
                <li>å…·æœ‰æ˜æ˜¾å±‚æ¬¡ç»“æ„çš„COé—®é¢˜</li>
                <li>å¤§è§„æ¨¡é—®é¢˜å®ä¾‹ï¼ˆå—ç›Šäºå±€éƒ¨æ³¨æ„åŠ›ï¼‰</li>
                <li>éœ€è¦å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦çš„åœºæ™¯</li>
                <li>åŒºåŸŸæ€§ç‰¹å¾æ˜æ˜¾çš„è·¯å¾„é—®é¢˜</li>
            </ul>
        """
    },
    "PolyNet": {
        "name": "PolyNet",
        "full_name": "Polynomial Time Network",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2021",
        "paper_url": "https://arxiv.org/abs/2102.09544",
        "paper_venue": "ICML 2021",
        "core_concept": """
            <p>PolyNet é€šè¿‡æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰å’ŒPolyakå¹³å‡æŠ€æœ¯æ¥ç¨³å®šç¥ç»ç½‘ç»œè®­ç»ƒï¼Œåœ¨ç»„åˆä¼˜åŒ–ä¸­å®ç°æ›´å¹³æ»‘çš„æ”¶æ•›è¿‡ç¨‹ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒæ€æƒ³</strong>ï¼šç»´æŠ¤æ¨¡å‹å‚æ•°çš„ç§»åŠ¨å¹³å‡å‰¯æœ¬ï¼Œåœ¨æ¨ç†æ—¶ä½¿ç”¨å¹³å‡åçš„å‚æ•°ï¼Œæ˜¾è‘—æå‡æ¨¡å‹ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. Polyakå¹³å‡æœºåˆ¶</h4>
            <ul>
                <li><strong>å‚æ•°å¹³æ»‘</strong>ï¼šÎ¸Ì„ = Î²Î¸Ì„ + (1-Î²)Î¸</li>
                <li><strong>è®­ç»ƒå‚æ•°</strong>ï¼šä½¿ç”¨æ ‡å‡†æ¢¯åº¦æ›´æ–°</li>
                <li><strong>æ¨ç†å‚æ•°</strong>ï¼šä½¿ç”¨å¹³å‡åçš„Î¸Ì„</li>
            </ul>
            
            <h4>2. åŒæ¨¡å‹æ¶æ„</h4>
            <ul>
                <li><strong>Onlineæ¨¡å‹</strong>ï¼šæ¥æ”¶æ¢¯åº¦æ›´æ–°</li>
                <li><strong>Targetæ¨¡å‹</strong>ï¼šå¹³æ»‘å‚æ•°å‰¯æœ¬</li>
                <li><strong>å®šæœŸåŒæ­¥</strong>ï¼šæ¯Næ­¥æ›´æ–°ä¸€æ¬¡targetæ¨¡å‹</li>
            </ul>
            
            <h4>3. è®­ç»ƒç­–ç•¥</h4>
            <ul>
                <li>ä½¿ç”¨onlineæ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—</li>
                <li>Targetæ¨¡å‹ç”¨äºç”Ÿæˆbaseline</li>
                <li>å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ¯è¡</li>
            </ul>
        """,
        "innovations": """
            <ul>
                <li>ğŸ”¹ <strong>å‚æ•°å¹³æ»‘</strong>ï¼šEMAé™ä½è®­ç»ƒå™ªå£°</li>
                <li>ğŸ”¹ <strong>ç¨³å®šBaseline</strong>ï¼šå¹³å‡æ¨¡å‹æä¾›æ›´ç¨³å®šçš„baseline</li>
                <li>ğŸ”¹ <strong>æ³›åŒ–æå‡</strong>ï¼šå¹³å‡å‚æ•°å…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§</li>
                <li>ğŸ”¹ <strong>å³æ’å³ç”¨</strong>ï¼šå¯åº”ç”¨äºä»»ä½•RLç®—æ³•</li>
            </ul>
        """,
        "performance": """
            <div class="info-grid">
                <div class="info-card">
                    <h5>TSP-50</h5>
                    <p>Gap: 1.20%<br>ç¨³å®šæ€§: â†‘â†‘</p>
                </div>
                <div class="info-card">
                    <h5>è®­ç»ƒæ”¶æ•›</h5>
                    <p>é€Ÿåº¦æå‡: 20%<br>æ–¹å·®é™ä½: 30%</p>
                </div>
            </div>
            <p style="margin-top: 1rem;">PolyNetä¸»è¦ä¼˜åŠ¿åœ¨äºè®­ç»ƒç¨³å®šæ€§ï¼Œè€Œéæœ€ç»ˆè§£è´¨é‡çš„æå‡ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>è®­ç»ƒæå…¶ç¨³å®š</li>
                <li>æ”¶æ•›æ›²çº¿å¹³æ»‘</li>
                <li>å‡å°‘è®­ç»ƒæ–¹å·®</li>
                <li>æ³›åŒ–èƒ½åŠ›å¼º</li>
                <li>å®ç°ç®€å•</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>é¢å¤–å†…å­˜å¼€é”€ï¼ˆåŒæ¨¡å‹ï¼‰</li>
                <li>éœ€è¦è°ƒæ•´å¹³å‡ç³»æ•°Î²</li>
                <li>å¯¹æœ€ç»ˆæ€§èƒ½æå‡æœ‰é™</li>
                <li>ä¸»è¦æ”¹å–„è®­ç»ƒè¿‡ç¨‹</li>
            </ul>
        """,
        "applications": """
            <p>PolyNetç‰¹åˆ«é€‚åˆï¼š</p>
            <ul>
                <li>è®­ç»ƒä¸ç¨³å®šçš„å¤§æ¨¡å‹</li>
                <li>éœ€è¦ç¨³å®šè®­ç»ƒçš„ç”Ÿäº§ç¯å¢ƒ</li>
                <li>ä½œä¸ºå…¶ä»–æ–¹æ³•çš„è¡¥å……æŠ€æœ¯</li>
                <li>è¶…å‚æ•°æ•æ„Ÿçš„åœºæ™¯</li>
            </ul>
        """
    },
    "MTPOMO": {
        "name": "MTPOMO",
        "full_name": "Multi-Task Policy Optimization with Multiple Optima",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2022",
        "paper_url": "https://arxiv.org/abs/2204.03236",
        "paper_venue": "NeurIPS 2022",
        "core_concept": """
            <p>MTPOMO å°†POMOæ‰©å±•åˆ°å¤šä»»åŠ¡å­¦ä¹ åœºæ™¯ï¼Œé€šè¿‡å…±äº«ç¼–ç å™¨åŒæ—¶å­¦ä¹ TSPã€CVRPã€OPç­‰å¤šç§ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå®ç°è·¨ä»»åŠ¡çŸ¥è¯†è¿ç§»å’Œè®­ç»ƒæ•ˆç‡æå‡ã€‚</p>
            <div class="highlight-box">
                <strong>æ ¸å¿ƒåˆ›æ–°</strong>ï¼šä½¿ç”¨ç»Ÿä¸€çš„ç¼–ç å™¨æå–é—®é¢˜æ— å…³çš„ç‰¹å¾ï¼Œé’ˆå¯¹ä¸åŒä»»åŠ¡ä½¿ç”¨ä¸“ç”¨çš„è§£ç å¤´ï¼Œåœ¨å¤šä»»åŠ¡é—´å…±äº«çŸ¥è¯†ï¼Œæå‡è®­ç»ƒæ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚
            </div>
        """,
        "architecture": """
            <h4>1. å…±äº«ç¼–ç å™¨</h4>
            <ul>
                <li><strong>Transformerç¼–ç å™¨</strong>ï¼šå¤„ç†æ‰€æœ‰ä»»åŠ¡çš„è¾“å…¥</li>
                <li><strong>ä»»åŠ¡æ— å…³ç‰¹å¾</strong>ï¼šæå–é€šç”¨çš„èŠ‚ç‚¹å’Œå›¾ç»“æ„ç‰¹å¾</li>
                <li><strong>å‚æ•°å…±äº«</strong>ï¼šæ‰€æœ‰ä»»åŠ¡å…±äº«ç¼–ç å™¨æƒé‡</li>
            </ul>
            
            <h4>2. ä»»åŠ¡ä¸“ç”¨è§£ç å™¨</h4>
            <ul>
                <li><strong>TSPè§£ç å™¨</strong>ï¼šé’ˆå¯¹æ—…è¡Œå•†é—®é¢˜çš„ç­–ç•¥ç½‘ç»œ</li>
                <li><strong>CVRPè§£ç å™¨</strong>ï¼šå¤„ç†å®¹é‡çº¦æŸçš„è·¯å¾„é—®é¢˜</li>
                <li><strong>OPè§£ç å™¨</strong>ï¼šé’ˆå¯¹å®šå‘é—®é¢˜çš„è§£ç é€»è¾‘</li>
            </ul>
            
            <h4>3. å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥</h4>
            <ul>
                <li>ä»»åŠ¡é‡‡æ ·ï¼šæ¯ä¸ªbatchéšæœºé€‰æ‹©ä»»åŠ¡</li>
                <li>æŸå¤±å¹³è¡¡ï¼šåŠ¨æ€è°ƒæ•´å„ä»»åŠ¡çš„æƒé‡</li>
                <li>æ¢¯åº¦å½’ä¸€åŒ–ï¼šé˜²æ­¢æŸä¸ªä»»åŠ¡ä¸»å¯¼è®­ç»ƒ</li>
            </ul>
        """,
        "innovations": """
            <ul>
                <li>ğŸ”¹ <strong>è·¨ä»»åŠ¡å­¦ä¹ </strong>ï¼šé¦–æ¬¡å°†POMOæ‰©å±•åˆ°å¤šä»»åŠ¡åœºæ™¯</li>
                <li>ğŸ”¹ <strong>çŸ¥è¯†è¿ç§»</strong>ï¼šä»»åŠ¡é—´å…±äº«ç¼–ç å™¨çŸ¥è¯†</li>
                <li>ğŸ”¹ <strong>è®­ç»ƒæ•ˆç‡</strong>ï¼šä¸€ä¸ªæ¨¡å‹è§£å†³å¤šä¸ªé—®é¢˜</li>
                <li>ğŸ”¹ <strong>é›¶æ ·æœ¬æ³›åŒ–</strong>ï¼šè®­ç»ƒè¿‡çš„æ¨¡å‹å¯é€‚åº”æ–°ä»»åŠ¡</li>
            </ul>
        """,
        "performance": """
            <div class="info-grid">
                <div class="info-card">
                    <h5>TSP-50</h5>
                    <p>Gap: 0.92%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>CVRP-50</h5>
                    <p>Gap: 4.12%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>OP-50</h5>
                    <p>Gap: 2.31%<br>Time: <1s</p>
                </div>
                <div class="info-card">
                    <h5>è®­ç»ƒæ•ˆç‡</h5>
                    <p>ç›¸æ¯”å•ä»»åŠ¡<br>æå‡: 3x</p>
                </div>
            </div>
            <p style="margin-top: 1rem;">MTPOMOåœ¨å„ä»»åŠ¡ä¸Šçš„æ€§èƒ½æ¥è¿‘ä¸“ç”¨æ¨¡å‹ï¼Œä½†è®­ç»ƒæ•ˆç‡æå‡æ˜¾è‘—ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>ä¸€ä¸ªæ¨¡å‹è§£å†³å¤šä¸ªé—®é¢˜</li>
                <li>è®­ç»ƒæ•ˆç‡é«˜ï¼ˆ3å€æå‡ï¼‰</li>
                <li>è·¨ä»»åŠ¡çŸ¥è¯†è¿ç§»</li>
                <li>æ³›åŒ–èƒ½åŠ›å¼º</li>
                <li>éƒ¨ç½²æˆæœ¬ä½</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>ä»»åŠ¡å¹³è¡¡å›°éš¾ï¼ˆæŸäº›ä»»åŠ¡å¯èƒ½è¢«å¿½è§†ï¼‰</li>
                <li>å†…å­˜å ç”¨å¤§ï¼ˆå¤šä¸ªè§£ç å™¨ï¼‰</li>
                <li>å•ä»»åŠ¡æ€§èƒ½ç•¥é€Šäºä¸“ç”¨æ¨¡å‹</li>
                <li>ä»»åŠ¡æ•°é‡å¢åŠ æ—¶æ‰©å±•æ€§æœ‰é™</li>
            </ul>
        """,
        "applications": """
            <p>MTPOMOç‰¹åˆ«é€‚åˆï¼š</p>
            <ul>
                <li>éœ€è¦è§£å†³å¤šç§COé—®é¢˜çš„ç”Ÿäº§ç¯å¢ƒ</li>
                <li>è®¡ç®—èµ„æºæœ‰é™ä½†é—®é¢˜ç±»å‹å¤šæ ·</li>
                <li>å¿«é€ŸåŸå‹å¼€å‘å’Œæµ‹è¯•</li>
                <li>ç ”ç©¶è·¨ä»»åŠ¡çŸ¥è¯†è¿ç§»</li>
            </ul>
        """
    },
    "MVMoE": {
        "name": "MVMoE",
        "full_name": "Multi-View Mixture of Experts",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>MVMoE ä½¿ç”¨æ··åˆä¸“å®¶æ¨¡å‹ï¼Œé’ˆå¯¹ä¸åŒç±»å‹çš„é—®é¢˜å®ä¾‹ä½¿ç”¨ä¸åŒçš„ä¸“å®¶ç½‘ç»œã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>é€‚åº”æ€§å¼º</li>
                <li>ä¸“ä¸šåŒ–å¤„ç†</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>æ¨¡å‹å¤æ‚</li>
                <li>è®­ç»ƒå›°éš¾</li>
            </ul>
        """
    },
    "L2D": {
        "name": "L2D",
        "full_name": "Learn to Delegate",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>L2D å­¦ä¹ ä½•æ—¶ä½¿ç”¨ç¥ç»ç½‘ç»œæ±‚è§£ï¼Œä½•æ—¶å§”æ‰˜ç»™ä¼ ç»Ÿå¯å‘å¼ç®—æ³•ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>çµæ´»æ€§é«˜</li>
                <li>ç»“åˆä¼˜åŠ¿</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>å†³ç­–å¤æ‚</li>
            </ul>
        """
    },
    "HGNN": {
        "name": "HGNN",
        "full_name": "Heterogeneous Graph Neural Network",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2022",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>HGNN ä½¿ç”¨å¼‚æ„å›¾ç¥ç»ç½‘ç»œå»ºæ¨¡ä¸åŒç±»å‹èŠ‚ç‚¹å’Œè¾¹çš„å…³ç³»ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>è¡¨è¾¾åŠ›å¼º</li>
                <li>é€‚ç”¨å¤æ‚é—®é¢˜</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è®¡ç®—å¼€é”€å¤§</li>
            </ul>
        """
    },
    "DF": {
        "name": "DF",
        "full_name": "Distribution Fitting",
        "category": "æ„é€ æ–¹æ³•ï¼ˆè‡ªå›å½’ï¼‰",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>DF é€šè¿‡æ‹Ÿåˆæœ€ä¼˜è§£çš„åˆ†å¸ƒæ¥ç”Ÿæˆé«˜è´¨é‡è§£ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>ç†è®ºä¼˜é›…</li>
                <li>æ€§èƒ½ä¼˜ç§€</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è®­ç»ƒå¤æ‚</li>
            </ul>
        """
    },
    "GFACS": {
        "name": "GFACS",
        "full_name": "Graph-based Fast Adaptive Construction Solver",
        "category": "æ„é€ æ–¹æ³•ï¼ˆéè‡ªå›å½’ï¼‰",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>GFACS ä½¿ç”¨å›¾ç¥ç»ç½‘ç»œéè‡ªå›å½’åœ°æ„å»ºè§£ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>é€Ÿåº¦æå¿«</li>
                <li>å®Œå…¨å¹¶è¡Œ</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è´¨é‡å¯èƒ½ä¸å¦‚è‡ªå›å½’æ–¹æ³•</li>
            </ul>
        """
    },
    "GLOP": {
        "name": "GLOP",
        "full_name": "Generalized Learning for Optimization Problems",
        "category": "æ„é€ æ–¹æ³•ï¼ˆéè‡ªå›å½’ï¼‰",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>GLOP æ˜¯ä¸€ä¸ªé€šç”¨çš„å­¦ä¹ æ¡†æ¶ï¼Œé€‚ç”¨äºå¤šç§ä¼˜åŒ–é—®é¢˜ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>é€šç”¨æ€§å¼º</li>
                <li>æ˜“äºæ‰©å±•</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>ç‰¹å®šé—®é¢˜æ€§èƒ½å¯èƒ½ä¸å¦‚ä¸“ç”¨æ–¹æ³•</li>
            </ul>
        """
    },
    "DACT": {
        "name": "DACT",
        "full_name": "Dual Attention with Cross Transformation",
        "category": "æ”¹è¿›æ–¹æ³•",
        "year": "2022",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>DACT ä½¿ç”¨åŒé‡æ³¨æ„åŠ›æœºåˆ¶å’Œäº¤å‰å˜æ¢æ¥æ”¹è¿›ç°æœ‰æ¨¡å‹ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>å³æ’å³ç”¨</li>
                <li>æ€§èƒ½æå‡æ˜æ˜¾</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è®¡ç®—å¼€é”€å¢åŠ </li>
            </ul>
        """
    },
    "N2S": {
        "name": "N2S",
        "full_name": "Neural to Symbolic",
        "category": "æ”¹è¿›æ–¹æ³•",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>N2S å°†ç¥ç»ç½‘ç»œçš„è¾“å‡ºè½¬æ¢ä¸ºç¬¦å·åŒ–çš„ä¼˜åŒ–ç®—æ³•ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>å¯è§£é‡Šæ€§å¼º</li>
                <li>è´¨é‡ä¼˜ç§€</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è½¬æ¢è¿‡ç¨‹å¤æ‚</li>
            </ul>
        """
    },
    "NeuOpt": {
        "name": "NeuOpt",
        "full_name": "Neural Optimizer",
        "category": "æ”¹è¿›æ–¹æ³•",
        "year": "2023",
        "paper_url": "#",
        "paper_venue": "Research Paper",
        "core_concept": """
            <p>NeuOpt ä½¿ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ ä¼˜åŒ–ç®—æ³•æœ¬èº«ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>å­¦ä¹ èƒ½åŠ›å¼º</li>
                <li>é€‚åº”æ€§å¥½</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>è®­ç»ƒå¤æ‚</li>
                <li>æ³›åŒ–æŒ‘æˆ˜</li>
            </ul>
        """
    },
    "ActiveSearch": {
        "name": "ActiveSearch",
        "full_name": "Active Search",
        "category": "ä¼ å¯¼å¼å¼ºåŒ–å­¦ä¹ ",
        "year": "2020",
        "paper_url": "https://arxiv.org/abs/2012.05417",
        "paper_venue": "ICLR 2021",
        "core_concept": """
            <p>Active Search åœ¨æµ‹è¯•æ—¶ç»§ç»­ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡ä¸»åŠ¨æœç´¢æ”¹è¿›è§£è´¨é‡ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>æµ‹è¯•æ—¶ä¼˜åŒ–</li>
                <li>è´¨é‡æå‡æ˜¾è‘—</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>æ¨ç†æ—¶é—´é•¿</li>
                <li>è®¡ç®—èµ„æºéœ€æ±‚é«˜</li>
            </ul>
        """
    },
    "EAS": {
        "name": "EAS",
        "full_name": "Efficient Active Search",
        "category": "ä¼ å¯¼å¼å¼ºåŒ–å­¦ä¹ ",
        "year": "2021",
        "paper_url": "https://arxiv.org/abs/2106.05126",
        "paper_venue": "NeurIPS 2021",
        "core_concept": """
            <p>EAS æ˜¯Active Searchçš„é«˜æ•ˆç‰ˆæœ¬ï¼Œå‡å°‘äº†æµ‹è¯•æ—¶ä¼˜åŒ–çš„è®¡ç®—å¼€é”€ã€‚</p>
        """,
        "advantages": """
            <ul>
                <li>æ›´å¿«çš„æµ‹è¯•æ—¶ä¼˜åŒ–</li>
                <li>æ•ˆç‡ä¸è´¨é‡å¹³è¡¡å¥½</li>
            </ul>
        """,
        "limitations": """
            <ul>
                <li>ä»éœ€é¢å¤–è®¡ç®—</li>
            </ul>
        """
    }
}

@app.route('/model_info')
@login_required
def model_info_list():
    """æ¨¡å‹çŸ¥è¯†åº“åˆ—è¡¨é¡µé¢"""
    # è·å–æ‰€æœ‰åˆ†ç±»
    categories = set()
    for model in MODEL_DATABASE.values():
        if 'category' in model:
            categories.add(model['category'])
    
    return render_template('model_list.html', 
                         models=MODEL_DATABASE, 
                         categories=sorted(categories),
                         active_page='model_info')

@app.route('/model_info/<model_id>')
@login_required
def model_info_detail(model_id):
    """æ¨¡å‹è¯¦æƒ…é¡µé¢"""
    if model_id not in MODEL_DATABASE:
        return "æ¨¡å‹ä¸å­˜åœ¨", 404
    
    model_data = MODEL_DATABASE[model_id]
    return render_template('model_info.html', model_data=model_data, active_page='model_info')

# ============================================
# æ—§çš„ register å’Œ login è·¯ç”±å·²è¢«æ–°çš„ API æ›¿ä»£ï¼Œå·²åˆ é™¤ ==========
#   æ–°è·¯ç”±åœ¨æ–‡ä»¶å¼€å¤´ï¼š/api/register, /api/login, /api/logout


# è‡ªå®šä¹‰ Lightning Callback ç”¨äºæ•è·è®­ç»ƒè¿›åº¦
class ProgressCallback(Callback):  # å®šä¹‰ä¸€ä¸ªå›è°ƒç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¶é›†ä¸æ¨é€æŒ‡æ ‡
    def __init__(self, queue, session_id, total_epochs, user_id):  # ========== æ·»åŠ user_idå‚æ•° ==========
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        self.queue = queue  # ä¿å­˜ä¸å‰ç«¯é€šä¿¡çš„æ¶ˆæ¯é˜Ÿåˆ—
        self.session_id = session_id  # ä¿å­˜å½“å‰è®­ç»ƒä¼šè¯ID
        self.total_epochs = total_epochs  # ä¿å­˜æ€»è®­ç»ƒè½®æ•°ï¼Œç”¨äºç™¾åˆ†æ¯”è®¡ç®—
        self.user_id = user_id  # ========== ä¿å­˜ç”¨æˆ·ID ==========
        self.best_reward = float('-inf')  # è®°å½•å†å²æœ€ä¼˜å¥–åŠ±ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        self.epoch_losses = []  # å­˜æ”¾å½“å‰epochå†…æ¯ä¸ªbatchçš„loss
        self.epoch_rewards = []  # å­˜æ”¾å½“å‰epochå†…æ¯ä¸ªbatchçš„reward
        # æ–°å¢ï¼šç”¨äºå­˜å‚¨æ‰€æœ‰epochçš„å†å²æ•°æ®ï¼Œç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾
        self.history_losses = []  # æ‰€æœ‰epochçš„å¹³å‡losså†å²
        self.history_rewards = []  # æ‰€æœ‰epochçš„å¹³å‡rewardå†å²
        self.history_epochs = []  # epochç¼–å·åˆ—è¡¨
        # ä¸ºåå°çº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥å’Œç®¡ç†å™¨
        self.db = None
        self.file_manager = None
    
    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):  # æ¯ä¸ªbatchç»“æŸæ—¶è¢«è°ƒç”¨
        """æ¯ä¸ª batch ç»“æŸæ—¶æ”¶é›†æŒ‡æ ‡"""  # è¯´æ˜æœ¬å‡½æ•°ç”¨é€”ï¼šæ”¶é›†batchçº§æŒ‡æ ‡
        # å°è¯•ä»å¤šä¸ªæ¥æºè·å– loss å’Œ reward  # å…¼å®¹ä¸åŒç‰ˆæœ¬/å®ç°çš„è¾“å‡ºç»“æ„
        loss_collected = False  # æ ‡è®°æ˜¯å¦å·²æˆåŠŸé‡‡é›†åˆ°loss
        reward_collected = False  # æ ‡è®°æ˜¯å¦å·²æˆåŠŸé‡‡é›†åˆ°reward
        
        # æ–¹æ³•1: ä» outputs è·å–  # é¦–é€‰ä»Lightningè¿”å›çš„outputsä¸­è¯»å–
        if outputs is not None and isinstance(outputs, dict):  # ç¡®è®¤outputsä¸ºå­—å…¸
            if 'loss' in outputs:  # å¦‚æœåŒ…å«lossé”®
                loss_val = outputs['loss']  # å–å‡ºlosså¼ é‡
                if isinstance(loss_val, torch.Tensor):  # ä¿è¯ç±»å‹ä¸ºTensor
                    self.epoch_losses.append(loss_val.item())  # è½¬ä¸ºæ ‡é‡å¹¶åŠ å…¥åˆ—è¡¨
                    loss_collected = True  # æ ‡è®°å·²é‡‡é›†åˆ°loss
            
            if 'reward' in outputs:  # å¦‚æœåŒ…å«rewardé”®
                reward_val = outputs['reward']  # å–å‡ºrewardå¼ é‡ï¼ˆå¯èƒ½æ˜¯batchç»´ï¼‰
                if isinstance(reward_val, torch.Tensor):  # ä¿è¯ç±»å‹ä¸ºTensor
                    self.epoch_rewards.append(reward_val.mean().item())  # å–å‡å€¼è½¬æ ‡é‡ååŠ å…¥åˆ—è¡¨
                    reward_collected = True  # æ ‡è®°å·²é‡‡é›†åˆ°reward
        
        # æ–¹æ³•2: ä» pl_module çš„ logged_metrics è·å–  # å¤‡é€‰ï¼šä»Lightningè®°å½•çš„æŒ‡æ ‡ä¸­è¯»å–
        if not loss_collected and hasattr(pl_module, 'log_dict') and hasattr(trainer, 'logged_metrics'):  # ä»…åœ¨æœªé‡‡é›†åˆ°lossæ—¶å°è¯•
            logged = trainer.logged_metrics  # è¯»å–å·²è®°å½•çš„æŒ‡æ ‡å­—å…¸
            if 'loss' in logged:  # å¦‚æœåŒ…å«loss
                loss_val = logged['loss']  # å–å‡ºlosså¼ é‡
                if isinstance(loss_val, torch.Tensor):  # ç±»å‹æ£€æŸ¥
                    self.epoch_losses.append(loss_val.item())  # è½¬ä¸ºæ ‡é‡å¹¶è®°å½•
        
        if not reward_collected and hasattr(pl_module, 'log_dict') and hasattr(trainer, 'logged_metrics'):  # æœªé‡‡é›†åˆ°rewardæ—¶å°è¯•
            logged = trainer.logged_metrics  # è¯»å–è®°å½•çš„æŒ‡æ ‡
            if 'reward' in logged:  # å¦‚æœåŒ…å«reward
                reward_val = logged['reward']  # å–å‡ºrewardå¼ é‡
                if isinstance(reward_val, torch.Tensor):  # ç±»å‹æ£€æŸ¥
                    self.epoch_rewards.append(reward_val.item())  # è½¬ä¸ºæ ‡é‡å¹¶è®°å½•
    
    def on_train_epoch_end(self, trainer, pl_module):  # æ¯ä¸ªepochç»“æŸæ—¶è¢«è°ƒç”¨
        """æ¯ä¸ªè®­ç»ƒ epoch ç»“æŸæ—¶è°ƒç”¨"""  # è¯´æ˜æœ¬å‡½æ•°ç”¨é€”ï¼šæ±‡æ€»å¹¶æ¨é€epochçº§æŒ‡æ ‡
        epoch = trainer.current_epoch + 1  # è·å–å½“å‰epochç¼–å·ï¼Œè½¬ä¸º1èµ·å§‹
        
        # é¦–å…ˆå°è¯•ä»ç´¯ç§¯çš„ batch æŒ‡æ ‡ä¸­è®¡ç®—å¹³å‡å€¼  # ä»¥batchæ±‡æ€»çš„æ–¹å¼è·å¾—æ›´ç¨³å®šçš„ç»Ÿè®¡
        loss = 0.0  # åˆå§‹åŒ–lossä¸º0
        reward = 0.0  # åˆå§‹åŒ–rewardä¸º0
        
        if self.epoch_losses:  # å¦‚æœæœ¬epochæ”¶é›†åˆ°äº†loss
            loss = sum(self.epoch_losses) / len(self.epoch_losses)  # è®¡ç®—losså‡å€¼
        
        if self.epoch_rewards:  # å¦‚æœæœ¬epochæ”¶é›†åˆ°äº†reward
            reward = sum(self.epoch_rewards) / len(self.epoch_rewards)  # è®¡ç®—rewardå‡å€¼
        
        # å¦‚æœæ²¡æœ‰ä» batch ä¸­è·å–åˆ°ï¼Œå°è¯•ä» metrics è·å–  # å…¼å®¹æŸäº›æƒ…å†µä¸‹outputsæœªè¿”å›æŒ‡æ ‡
        if loss == 0.0 or reward == 0.0:  # åªè¦æœ‰ä¸€ä¸ªä¸º0åˆ™å°è¯•å›é€€
            metrics = trainer.callback_metrics  # ä»Lightningå›è°ƒæŒ‡æ ‡ä¸­è¯»å–
            
            # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰å¯ç”¨çš„æŒ‡æ ‡é”®åï¼ˆä»…ç¬¬ä¸€ä¸ªepochï¼‰  # ä¾¿äºè¯†åˆ«å…·ä½“æŒ‡æ ‡é”®
            if epoch == 1:  # ä»…åœ¨é¦–ä¸ªepochæ‰“å°ï¼Œé¿å…åˆ·å±
                self.queue.put(json.dumps({  # é€šè¿‡é˜Ÿåˆ—å‘å‰ç«¯å‘é€ä¿¡æ¯
                    'type': 'info',  # æ¶ˆæ¯ç±»å‹ä¸ºinfo
                    'message': f'å¯ç”¨çš„ callback_metrics é”®: {list(metrics.keys())}'  # åˆ—å‡ºcallback_metricsé”®
                }))
                if hasattr(trainer, 'logged_metrics'):  # å¦‚æœå­˜åœ¨logged_metrics
                    self.queue.put(json.dumps({  # å†å‘é€ä¸€æ¡æ¶ˆæ¯
                        'type': 'info',  # ä¿¡æ¯ç±»å‹
                        'message': f'å¯ç”¨çš„ logged_metrics é”®: {list(trainer.logged_metrics.keys())}'  # åˆ—å‡ºlogged_metricsé”®
                    }))
            
            # RL4CO çš„ REINFORCE æ¨¡å‹ä½¿ç”¨çš„é”®å  # ä¾æ¬¡å°è¯•å¸¸è§é”®å
            if loss == 0.0:  # è‹¥lossä»æœªå¾—åˆ°
                loss = metrics.get('loss', metrics.get('train_loss', metrics.get('train/loss', 0.0)))  # å¤šé”®åå›é€€
            if reward == 0.0:  # è‹¥rewardä»æœªå¾—åˆ°
                reward = metrics.get('reward', metrics.get('train_reward', metrics.get('train/reward', 0.0)))  # å¤šé”®åå›é€€
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä» logged_metrics è·å–  # æœ€åå›é€€åˆ°logged_metrics
            if loss == 0.0 and hasattr(trainer, 'logged_metrics'):  # è‹¥ä»ä¸º0å¹¶ä¸”å­˜åœ¨logged_metrics
                logged = trainer.logged_metrics  # è¯»å–logged_metrics
                loss = logged.get('loss', logged.get('train_loss', logged.get('train/loss', 0.0)))  # å¤šé”®åå›é€€
            
            if reward == 0.0 and hasattr(trainer, 'logged_metrics'):  # è‹¥ä»ä¸º0å¹¶ä¸”å­˜åœ¨logged_metrics
                logged = trainer.logged_metrics  # è¯»å–logged_metrics
                reward = logged.get('reward', logged.get('train_reward', logged.get('train/reward', 0.0)))  # å¤šé”®åå›é€€
            
            if isinstance(loss, torch.Tensor):  # å¦‚æœlossè¿˜æ˜¯å¼ é‡
                loss = loss.item()  # è½¬ä¸ºæ ‡é‡
            if isinstance(reward, torch.Tensor):  # å¦‚æœrewardè¿˜æ˜¯å¼ é‡
                reward = reward.item()  # è½¬ä¸ºæ ‡é‡
        
        # æ¸…ç©ºæœ¬ epoch çš„ç´¯ç§¯æŒ‡æ ‡  # ä¸ºä¸‹ä¸€ä¸ªepochåšå‡†å¤‡
        self.epoch_losses = []  # é‡ç½®lossåˆ—è¡¨
        self.epoch_rewards = []  # é‡ç½®rewardåˆ—è¡¨
        
        self.best_reward = max(self.best_reward, reward)  # æ›´æ–°å†å²æœ€ä¼˜reward
        progress = (epoch / self.total_epochs) * 100  # è®¡ç®—è®­ç»ƒè¿›åº¦ç™¾åˆ†æ¯”
        
        # æ–°å¢ï¼šè®°å½•å†å²æ•°æ®ç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾
        self.history_epochs.append(epoch)
        self.history_losses.append(loss)
        self.history_rewards.append(reward)
        
        # æ–°å¢ï¼šç”Ÿæˆå®æ—¶è®­ç»ƒæ›²çº¿å›¾
        try:
            USER_PLOTS_DIR = get_user_plot_dir(self.user_id)  # è·å–ç”¨æˆ·ä¸“å±ç›®å½•
            plot_filename = f"training_curves_{self.session_id[:8]}.png"
            plot_path = os.path.join(USER_PLOTS_DIR, plot_filename)  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
            
            # åˆ›å»ºåŒ…å«losså’Œrewardçš„åŒå­å›¾
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
            
            # ç»˜åˆ¶Lossæ›²çº¿
            ax1.plot(self.history_epochs, self.history_losses, 'b-o', linewidth=2, markersize=6, label='Loss')
            ax1.set_xlabel('Epoch', fontsize=12)
            ax1.set_ylabel('Loss', fontsize=12)
            ax1.set_title('è®­ç»ƒLosså˜åŒ–æ›²çº¿', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.3, linestyle='--')
            ax1.legend(loc='upper right', fontsize=10)
            
            # ç»˜åˆ¶Rewardæ›²çº¿
            ax2.plot(self.history_epochs, self.history_rewards, 'g-o', linewidth=2, markersize=6, label='Reward')
            ax2.set_xlabel('Epoch', fontsize=12)
            ax2.set_ylabel('Reward', fontsize=12)
            ax2.set_title('è®­ç»ƒRewardå˜åŒ–æ›²çº¿', fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3, linestyle='--')
            ax2.legend(loc='lower right', fontsize=10)
            
            # åœ¨rewardå›¾ä¸Šæ ‡æ³¨æœ€ä½³reward
            best_epoch_idx = self.history_rewards.index(max(self.history_rewards))
            best_epoch_num = self.history_epochs[best_epoch_idx]
            ax2.axhline(y=self.best_reward, color='r', linestyle='--', alpha=0.5, label=f'Best: {self.best_reward:.4f}')
            ax2.scatter([best_epoch_num], [self.best_reward], color='red', s=100, zorder=5, marker='*')
            ax2.legend(loc='lower right', fontsize=10)
            
            plt.tight_layout()
            plt.savefig(plot_path, dpi=150, bbox_inches="tight")
            plt.close(fig)
            
            # ========== ä¿å­˜æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“ ==========
            if self.file_manager is None:
                self.db = get_background_db()
                if self.db:
                    self.file_manager = FileManager(self.db)
            
            if self.file_manager:
                try:
                    self.file_manager.save_file_record(
                        user_id=self.user_id,
                        session_id=self.session_id,
                        filename=plot_filename,
                        file_type='curve',
                        file_path=plot_path
                    )
                except Exception as e:
                    print(f"ä¿å­˜æ–‡ä»¶è®°å½•å¤±è´¥: {str(e)}")
            
            # é€šè¿‡é˜Ÿåˆ—å‘é€å›¾è¡¨è·¯å¾„
            self.queue.put(json.dumps({
                'type': 'plot',
                'plot_url': f"/static/model_plots/user_{self.user_id}/{plot_filename}",  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
                'message': f'Epoch {epoch} è®­ç»ƒæ›²çº¿å·²æ›´æ–°'
            }))
        except Exception as e:
            self.queue.put(json.dumps({
                'type': 'warning',
                'message': f'ç”Ÿæˆè®­ç»ƒæ›²çº¿å¤±è´¥: {str(e)}'
            }))
        
        # æ›´æ–°è®­ç»ƒçŠ¶æ€  # å°†æœ€æ–°æŒ‡æ ‡å†™å…¥å…¨å±€çŠ¶æ€ï¼Œä¾›æŸ¥è¯¢æ¥å£ä½¿ç”¨
        training_status[self.session_id].update({
            'progress': progress,  # å½“å‰è¿›åº¦ç™¾åˆ†æ¯”
            'epoch': epoch,  # å½“å‰epochç¼–å·
            'loss': round(loss, 4),  # æœ¬epochå¹³å‡lossï¼ˆå››èˆäº”å…¥ï¼‰
            'reward': round(reward, 4),  # æœ¬epochå¹³å‡rewardï¼ˆå››èˆäº”å…¥ï¼‰
            'best_reward': round(self.best_reward, 4),  # å†å²æœ€ä¼˜rewardï¼ˆå››èˆäº”å…¥ï¼‰
            'plot_url': f"/static/model_plots/user_{self.user_id}/training_curves_{self.session_id[:8]}.png"  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
        })
        
        # å‘é€è¿›åº¦æ›´æ–°  # ä»¥SSEæ¶ˆæ¯å½¢å¼æ¨é€è¿›åº¦åˆ°å‰ç«¯
        self.queue.put(json.dumps({
            'type': 'progress',  # æ¶ˆæ¯ç±»å‹ï¼šè¿›åº¦
            'epoch': epoch,  # å½“å‰epoch
            'total_epochs': self.total_epochs,  # æ€»epochæ•°
            'progress': round(progress, 2),  # è¿›åº¦ç™¾åˆ†æ¯”ä¿ç•™ä¸¤ä½
            'loss': round(loss, 4),  # å¹³å‡loss
            'reward': round(reward, 4),  # å¹³å‡reward
            'best_reward': round(self.best_reward, 4)  # å†å²æœ€ä¼˜reward
        }))
        
        # å‘é€è¯¦ç»†ä¿¡æ¯  # é¢å¤–ä»¥infoå½¢å¼å‘é€å¯è¯»å­—ç¬¦ä¸²
        self.queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹ï¼šä¿¡æ¯
            'message': f'Epoch {epoch}/{self.total_epochs} - Loss: {loss:.4f}, Reward: {reward:.4f}, Best: {self.best_reward:.4f}'  # æ ¼å¼åŒ–çš„è®­ç»ƒæ‘˜è¦
        }))


# çœŸå®çš„ RL4CO è®­ç»ƒå‡½æ•°
def real_rl4co_training(config, session_id, user_id):  # ========== æ·»åŠ user_idå‚æ•° ==========
    """ä½¿ç”¨ RL4CO è¿›è¡ŒçœŸå®çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒ"""  # å‡½æ•°è¯´æ˜ï¼šçœŸå®è®­ç»ƒæ¨¡å¼
    queue = training_queues[session_id]  # å–å‡ºå½“å‰ä¼šè¯çš„æ¶ˆæ¯é˜Ÿåˆ—
    
    # ========== ä¸ºåå°çº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥ ==========
    bg_db = get_background_db()
    bg_session_manager = TrainingSessionManager(bg_db) if bg_db else None
    bg_file_manager = FileManager(bg_db) if bg_db else None
    
    try:  # æ•è·è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¼‚å¸¸
        # ========== åˆ›å»ºç”¨æˆ·ä¸“å±ç›®å½• ==========
        USER_PLOTS_DIR = get_user_plot_dir(user_id)
        USER_CHECKPOINTS_DIR = get_user_checkpoint_dir(user_id)
        
        # åˆå§‹åŒ–è®­ç»ƒçŠ¶æ€  # ä¸ºå‰ç«¯å±•ç¤ºå‡†å¤‡é»˜è®¤çŠ¶æ€
        training_status[session_id] = {
            'status': 'running',  # æ ‡è®°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            'progress': 0,  # åˆå§‹è¿›åº¦0
            'epoch': 0,  # å½“å‰epochä¸º0
            'loss': 0,  # åˆå§‹lossä¸º0
            'reward': 0,  # åˆå§‹rewardä¸º0
            'best_reward': 0  # åˆå§‹bestä¸º0
        }
        
        # è·å–é…ç½®å‚æ•°  # ä»è¯·æ±‚é…ç½®ä¸­è§£æè®­ç»ƒè¶…å‚
        epochs = int(config.get('epochs', 3))  # è®­ç»ƒè½®æ•°ï¼Œé»˜è®¤3
        model_type = config.get('model', 'attention')  # æ¨¡å‹ç±»å‹ï¼Œé»˜è®¤attention
        problem_type = config.get('problem', 'tsp')  # é—®é¢˜ç±»å‹ï¼Œé»˜è®¤tsp
        batch_size = int(config.get('batch_size', 512))  # batchå¤§å°ï¼Œé»˜è®¤512
        learning_rate = float(config.get('learning_rate', 1e-4))  # å­¦ä¹ ç‡ï¼Œé»˜è®¤1e-4
        num_loc = 50  # é—®é¢˜è§„æ¨¡ï¼ˆTSPç‚¹æ•°ï¼‰
        
        # å‘é€è®­ç»ƒå¼€å§‹æ¶ˆæ¯  # å‘ŠçŸ¥å‰ç«¯è®­ç»ƒå·²å¯åŠ¨åŠé…ç½®ä¿¡æ¯
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': f'å¼€å§‹è®­ç»ƒ {model_type.upper()} æ¨¡å‹ï¼Œé—®é¢˜ç±»å‹: {problem_type.upper()}'  # æ–‡æœ¬å†…å®¹
        }))
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': f'é…ç½®: Epochs={epochs}, Batch={batch_size}, LR={learning_rate}, é—®é¢˜è§„æ¨¡={num_loc}'  # é…ç½®è¯¦æƒ…
        }))
        
        # æ£€æµ‹è®¾å¤‡  # è‡ªåŠ¨é€‰æ‹©GPUæˆ–CPU
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # PyTorchè®¾å¤‡
        accelerator = "gpu" if torch.cuda.is_available() else "cpu"  # LightningåŠ é€Ÿå™¨ç±»å‹
        devices = 1 if torch.cuda.is_available() else "auto"  # è®¾å¤‡æ•°é‡è®¾ç½®
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': f'ä½¿ç”¨è®¾å¤‡: {device}'  # å±•ç¤ºè®¾å¤‡ä¿¡æ¯
        }))
        
        # åˆå§‹åŒ–ç¯å¢ƒ  # æ ¹æ®é—®é¢˜ç±»å‹æ„é€ ç¯å¢ƒ
        if problem_type.lower() == 'tsp':  # TSPé—®é¢˜
            env = TSPEnv(generator_params={'num_loc': num_loc})  # åˆ›å»ºTSPç¯å¢ƒ
        elif problem_type.lower() == 'cvrp':  # CVRPé—®é¢˜
            env = CVRPEnv(generator_params={'num_loc': num_loc})  # åˆ›å»ºCVRPç¯å¢ƒ
        else:  # å…¶ä»–æƒ…å†µé»˜è®¤TSP
            env = TSPEnv(generator_params={'num_loc': num_loc})  # åˆ›å»ºé»˜è®¤TSPç¯å¢ƒ
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': f'ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ: {env.name}'  # ç¯å¢ƒåç§°åé¦ˆ
        }))
        
        # å®šä¹‰ç­–ç•¥ç½‘ç»œ  # æ„å»ºæ³¨æ„åŠ›æ¨¡å‹ç­–ç•¥
        policy = AttentionModelPolicy(
            env_name=env.name,  # æŒ‡å®šç¯å¢ƒåï¼Œä»¥åŒ¹é…è¾“å…¥è¾“å‡º
            embed_dim=128,  # åµŒå…¥ç»´åº¦
            num_encoder_layers=3,  # ç¼–ç å™¨å±‚æ•°
            num_heads=8,  # å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        )
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': 'ç­–ç•¥ç½‘ç»œåˆå§‹åŒ–å®Œæˆ'  # ç­–ç•¥æ„å»ºå®Œæˆ
        }))
        
        # å®šä¹‰ RL æ¨¡å‹  # ä½¿ç”¨REINFORCEç­–ç•¥æ¢¯åº¦
        model = REINFORCE(
            env,  # ä¼ å…¥ç¯å¢ƒ
            policy,  # ä¼ å…¥ç­–ç•¥ç½‘ç»œ
            baseline="rollout",  # åŸºçº¿ç±»å‹ï¼Œé‡‡ç”¨rollout baseline
            batch_size=batch_size,  # è®­ç»ƒbatchå¤§å°
            train_data_size=10_000,  # å‡å°‘è®­ç»ƒæ•°æ®é‡ä»¥æå‡é€Ÿåº¦
            val_data_size=1_000,  # éªŒè¯æ•°æ®é‡
            optimizer_kwargs={"lr": learning_rate},  # ä¼˜åŒ–å™¨è¶…å‚
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„ checkpoint  # æ”¯æŒæ–­ç‚¹ç»­è®­
        checkpoint_path = os.path.join(USER_CHECKPOINTS_DIR, f"{problem_type}-{model_type}.ckpt")  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
        ckpt_path = checkpoint_path if os.path.exists(checkpoint_path) else None  # è‹¥å­˜åœ¨åˆ™ä½¿ç”¨
        
        if ckpt_path:  # å¦‚æœæ‰¾åˆ°äº†å†å²ckpt
            queue.put(json.dumps({
                'type': 'info',  # æ¶ˆæ¯ç±»å‹
                'message': f'åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}'  # æç¤ºå·²åŠ è½½
            }))
        
        # åˆ›å»ºè¿›åº¦å›è°ƒ  # æ„å»ºè‡ªå®šä¹‰å›è°ƒä»¥æ¨é€æŒ‡æ ‡
        progress_callback = ProgressCallback(queue, session_id, epochs, user_id)  # ========== ä¼ å…¥user_id ==========
        
        # åˆå§‹åŒ–è®­ç»ƒå™¨  # æ„å»ºLightningè®­ç»ƒå™¨
        trainer = RL4COTrainer(
            max_epochs=epochs,  # æœ€å¤§å…¨è®­ç»ƒè½®æ•°
            accelerator=accelerator,  # åŠ é€Ÿå™¨è®¾ç½®
            devices=devices,  # è®¾å¤‡é…ç½®
            callbacks=[progress_callback],  # æ³¨å†Œå›è°ƒ
            logger=None,  # å…³é—­é»˜è®¤æ—¥å¿—è®°å½•å™¨
            enable_progress_bar=False,  # å…³é—­è¿›åº¦æ¡
            enable_model_summary=False,  # å…³é—­æ¨¡å‹æ‘˜è¦
        )
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': 'å¼€å§‹è®­ç»ƒ...'  # æç¤ºè®­ç»ƒå¼€å§‹
        }))
        
        # å¼€å§‹è®­ç»ƒ  # æ‰§è¡Œfitï¼Œæ”¯æŒä»ckptç»§ç»­
        if ckpt_path:  # è‹¥å­˜åœ¨ckptåˆ™ä»ckptç»§ç»­
            trainer.fit(model, ckpt_path=ckpt_path)  # å¸¦ckptè®­ç»ƒ
        else:  # å¦åˆ™ä»å¤´è®­ç»ƒ
            trainer.fit(model)  # ç›´æ¥è®­ç»ƒ
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': 'è®­ç»ƒå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆå¯è§†åŒ–ç»“æœ...'  # è®­ç»ƒç»“æŸæç¤º
        }))
        
        # è®­ç»ƒåæµ‹è¯•å¹¶ç”Ÿæˆå¯è§†åŒ–  # å¯¹æ¯”éšæœºç­–ç•¥ä¸è®­ç»ƒåç­–ç•¥
        policy = model.policy.to(device)  # å°†ç­–ç•¥ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
        td_init = env.reset(batch_size=[3]).to(device)  # ç”Ÿæˆ3ä¸ªæµ‹è¯•å®ä¾‹å¹¶æ”¾åˆ°è®¾å¤‡
        
        # æœªè®­ç»ƒæ¨¡å‹æµ‹è¯•ï¼ˆä½¿ç”¨éšæœºç­–ç•¥ï¼‰  # é‡‡æ ·è§£ç æ¨¡æ‹Ÿæœªè®­ç»ƒè¡¨ç°
        out_untrained = policy(td_init.clone(), phase="test", decode_type="sampling", return_actions=True)  # å‰å‘è®¡ç®—
        actions_untrained = out_untrained['actions'].cpu().detach()  # æå–åŠ¨ä½œå¹¶è½¬CPU
        rewards_untrained = out_untrained['reward'].cpu().detach()  # æå–å¥–åŠ±å¹¶è½¬CPU
        
        # è®­ç»ƒåæ¨¡å‹æµ‹è¯•  # è´ªå¿ƒè§£ç è¯„ä¼°è®­ç»ƒåæ€§èƒ½
        out_trained = policy(td_init.clone(), phase="test", decode_type="greedy", return_actions=True)  # å‰å‘è®¡ç®—
        actions_trained = out_trained['actions'].cpu().detach()  # æå–åŠ¨ä½œå¹¶è½¬CPU
        rewards_trained = out_trained['reward'].cpu().detach()  # æå–å¥–åŠ±å¹¶è½¬CPU
        
        # ç”Ÿæˆå¯¹æ¯”å›¾  # å¯è§†åŒ–éšæœºä¸è®­ç»ƒåè·¯å¾„åŠä»£ä»·
        plot_paths = []  # å­˜å‚¨ç”Ÿæˆå›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„
        animation_paths = []  # å­˜å‚¨åŠ¨æ€GIFçš„è·¯å¾„
        
        for i, td in enumerate(td_init):  # éå†æ¯ä¸ªæµ‹è¯•å®ä¾‹
            # ç”Ÿæˆé™æ€å¯¹æ¯”å›¾
            fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # åˆ›å»ºå·¦å³ä¸¤ä¸ªå­å›¾
            env.render(td, actions_untrained[i], ax=axs[0])  # å·¦å›¾æ¸²æŸ“éšæœºç­–ç•¥è·¯å¾„
            env.render(td, actions_trained[i], ax=axs[1])  # å³å›¾æ¸²æŸ“è®­ç»ƒåç­–ç•¥è·¯å¾„
            axs[0].set_title(f"Random | Cost = {-rewards_untrained[i].item():.3f}")  # å·¦å›¾æ ‡é¢˜ï¼šéšæœºç­–ç•¥æˆæœ¬
            axs[1].set_title(f"Trained | Cost = {-rewards_trained[i].item():.3f}")  # å³å›¾æ ‡é¢˜ï¼šè®­ç»ƒåæˆæœ¬
            
            plot_filename = f"comparison_{session_id[:8]}_{i+1}.png"  # ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶åï¼ˆå«ä¼šè¯å‰ç¼€ï¼‰
            plot_path = os.path.join(USER_PLOTS_DIR, plot_filename)  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
            plt.savefig(plot_path, dpi=150, bbox_inches="tight")  # ä¿å­˜å›¾ç‰‡åˆ°ç£ç›˜
            plt.close()  # å…³é—­å›¾åƒä»¥é‡Šæ”¾å†…å­˜
            
            # ========== ä¿å­˜æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“ ==========
            if bg_file_manager:
                try:
                    bg_file_manager.save_file_record(
                        user_id=user_id,
                        session_id=session_id,
                        filename=plot_filename,
                        file_type='plot',
                        file_path=plot_path
                    )
                except Exception as e:
                    print(f"ä¿å­˜æ–‡ä»¶è®°å½•å¤±è´¥: {str(e)}")
            
            plot_paths.append(f"/static/model_plots/user_{user_id}/{plot_filename}")  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
            
            # ç”ŸæˆåŠ¨æ€è·¯çº¿æ„å»ºè¿‡ç¨‹GIF
            queue.put(json.dumps({
                'type': 'info',
                'message': f'æ­£åœ¨ç”ŸæˆåŠ¨æ€è·¯çº¿å›¾ {i+1}/3...'
            }))
            
            animation_filename = f"animation_{session_id[:8]}_{i+1}.gif"
            animation_path = os.path.join(USER_PLOTS_DIR, animation_filename)  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
            
            # ç”Ÿæˆè®­ç»ƒåè·¯çº¿çš„é€æ­¥æ„å»ºåŠ¨ç”»
            create_route_animation(
                td, 
                actions_trained[i].cpu().numpy(), 
                animation_path,
                title="è®­ç»ƒåè·¯çº¿ç”Ÿæˆè¿‡ç¨‹"
            )
            
            # ========== ä¿å­˜æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“ ==========
            if bg_file_manager:
                try:
                    bg_file_manager.save_file_record(
                        user_id=user_id,
                        session_id=session_id,
                        filename=animation_filename,
                        file_type='animation',
                        file_path=animation_path
                    )
                except Exception as e:
                    print(f"ä¿å­˜æ–‡ä»¶è®°å½•å¤±è´¥: {str(e)}")
            
            animation_paths.append(f"/static/model_plots/user_{user_id}/{animation_filename}")  # ========== ä½¿ç”¨ç”¨æˆ·ç›®å½• ==========
        
        # ä¿å­˜æ£€æŸ¥ç‚¹  # å°†æœ€ç»ˆæ¨¡å‹æƒé‡ä¿å­˜åˆ°æ–‡ä»¶
        trainer.save_checkpoint(checkpoint_path)  # ä¿å­˜ckpt
        
        # ========== ä¿å­˜checkpointæ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“ ==========
        if bg_file_manager:
            try:
                checkpoint_filename = os.path.basename(checkpoint_path)
                bg_file_manager.save_file_record(
                    user_id=user_id,
                    session_id=session_id,
                    filename=checkpoint_filename,
                    file_type='checkpoint',
                    file_path=checkpoint_path
                )
            except Exception as e:
                print(f"ä¿å­˜checkpointè®°å½•å¤±è´¥: {str(e)}")
        
        queue.put(json.dumps({
            'type': 'info',  # æ¶ˆæ¯ç±»å‹
            'message': f'æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}'  # ä¿å­˜æˆåŠŸæç¤º
        }))
        
        # è®­ç»ƒå®Œæˆ  # æ±‡æ€»æœ€ç»ˆç»“æœå¹¶é€šçŸ¥å‰ç«¯
        training_status[session_id]['status'] = 'completed'  # æ ‡è®°çŠ¶æ€ä¸ºå·²å®Œæˆ
        
        # ========== æ›´æ–°è®­ç»ƒä¼šè¯çŠ¶æ€åˆ°æ•°æ®åº“ ==========
        if bg_session_manager:
            try:
                from datetime import datetime
                bg_session_manager.update_session(
                    session_id=session_id,
                    status='completed',
                    end_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    final_loss=training_status[session_id]['loss'],
                    final_reward=training_status[session_id]['reward'],
                    best_reward=training_status[session_id]['best_reward'],
                    checkpoint_path=checkpoint_path
                )
            except Exception as e:
                print(f"æ›´æ–°è®­ç»ƒä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}")
        
        final_results = {
            'model': model_type,  # æ¨¡å‹ç±»å‹
            'problem': problem_type,  # é—®é¢˜ç±»å‹
            'strategy': 'REINFORCE',  # è®­ç»ƒç­–ç•¥
            'total_epochs': epochs,  # æ€»è®­ç»ƒè½®æ•°
            'final_loss': training_status[session_id]['loss'],  # æœ€ç»ˆloss
            'final_reward': training_status[session_id]['reward'],  # æœ€ç»ˆreward
            'best_reward': training_status[session_id]['best_reward'],  # å†å²æœ€ä¼˜reward
            'plot_paths': plot_paths,  # å¯è§†åŒ–å›¾ç‰‡è·¯å¾„
            'animation_paths': animation_paths,  # åŠ¨æ€GIFè·¯å¾„
            'training_curve': training_status[session_id].get('plot_url', ''),  # è®­ç»ƒæ›²çº¿å›¾è·¯å¾„
            'checkpoint_path': checkpoint_path  # æ¨¡å‹ckptè·¯å¾„
        }
        
        queue.put(json.dumps({
            'type': 'complete',  # æ¶ˆæ¯ç±»å‹ï¼šå®Œæˆ
            'message': 'è®­ç»ƒå®Œæˆï¼',  # å®Œæˆæç¤º
            'results': final_results  # é™„å¸¦æœ€ç»ˆç»“æœæ•°æ®
        }))
        
    except Exception as e:  # å¼‚å¸¸å¤„ç†åˆ†æ”¯
        import traceback  # å¼•å…¥tracebackç”¨äºå †æ ˆä¿¡æ¯
        error_msg = f'{str(e)}\n{traceback.format_exc()}'  # ç»„è£…é”™è¯¯ä¸å †æ ˆæ–‡æœ¬ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        training_status[session_id]['status'] = 'error'  # å°†çŠ¶æ€ç½®ä¸ºé”™è¯¯
        
        # ========== æ›´æ–°è®­ç»ƒä¼šè¯çŠ¶æ€ä¸ºå¤±è´¥ ==========
        if bg_session_manager:
            try:
                from datetime import datetime
                bg_session_manager.update_session(
                    session_id=session_id,
                    status='failed',
                    end_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                )
            except Exception as update_error:
                print(f"æ›´æ–°å¤±è´¥çŠ¶æ€å¤±è´¥: {str(update_error)}")
        
        queue.put(json.dumps({  # å‘å‰ç«¯æ¨é€é”™è¯¯æ¶ˆæ¯
            'type': 'error',  # æ¶ˆæ¯ç±»å‹ï¼šé”™è¯¯
            'message': f'è®­ç»ƒå‡ºé”™: {str(e)}'  # é”™è¯¯æè¿°
        }))
    
    finally:
        # å…³é—­åå°æ•°æ®åº“è¿æ¥
        if bg_db:
            try:
                bg_db.close()
            except:
                pass


# æ¨¡æ‹Ÿè®­ç»ƒå‡½æ•°ï¼ˆå¤‡ç”¨ï¼‰
def simulate_training(config, session_id, user_id):  # ========== æ·»åŠ user_idå‚æ•° ==========
    """æ¨¡æ‹Ÿå¼ºåŒ–å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ï¼ˆå½“ RL4CO ä¸å¯ç”¨æ—¶ï¼‰"""
    queue = training_queues[session_id]
    
    try:
        training_status[session_id] = {
            'status': 'running',
            'progress': 0,
            'epoch': 0,
            'loss': 0,
            'reward': 0,
            'best_reward': 0
        }
        
        epochs = int(config.get('epochs', 10))
        model = config.get('model', 'attention')
        problem = config.get('problem', 'tsp')
        
        queue.put(json.dumps({
            'type': 'info',
            'message': f'[æ¨¡æ‹Ÿæ¨¡å¼] å¼€å§‹è®­ç»ƒ {model.upper()} æ¨¡å‹ï¼Œé—®é¢˜ç±»å‹: {problem.upper()}'
        }))
        
        for epoch in range(1, epochs + 1):
            time.sleep(0.5)
            
            import random
            progress = (epoch / epochs) * 100
            loss = 10 * (1 - epoch / epochs) + random.uniform(0, 0.5)
            reward = -20 + (15 * epoch / epochs) + random.uniform(-1, 1)
            best_reward = max(training_status[session_id].get('best_reward', float('-inf')), reward)
            
            training_status[session_id].update({
                'progress': progress,
                'epoch': epoch,
                'loss': round(loss, 4),
                'reward': round(reward, 4),
                'best_reward': round(best_reward, 4)
            })
            
            queue.put(json.dumps({
                'type': 'progress',
                'epoch': epoch,
                'total_epochs': epochs,
                'progress': round(progress, 2),
                'loss': round(loss, 4),
                'reward': round(reward, 4),
                'best_reward': round(best_reward, 4)
            }))
            
            if epoch % 2 == 0 or epoch == epochs:
                queue.put(json.dumps({
                    'type': 'info',
                    'message': f'Epoch {epoch}/{epochs} - Loss: {loss:.4f}, Reward: {reward:.4f}'
                }))
        
        training_status[session_id]['status'] = 'completed'
        queue.put(json.dumps({
            'type': 'complete',
            'message': '[æ¨¡æ‹Ÿæ¨¡å¼] è®­ç»ƒå®Œæˆï¼',
            'results': {
                'model': model,
                'problem': problem,
                'strategy': 'REINFORCE',
                'total_epochs': epochs,
                'final_loss': training_status[session_id]['loss'],
                'final_reward': training_status[session_id]['reward'],
                'best_reward': training_status[session_id]['best_reward']
            }
        }))
        
    except Exception as e:
        training_status[session_id]['status'] = 'error'
        queue.put(json.dumps({
            'type': 'error',
            'message': f'è®­ç»ƒå‡ºé”™: {str(e)}'
        }))


@app.route('/api/start_training', methods=['POST'])
@login_required
def start_training():
    """æ¥æ”¶è®­ç»ƒé…ç½®å¹¶å¯åŠ¨è®­ç»ƒ - éœ€è¦ç™»å½•"""
    try:
        # ========== è·å–å½“å‰ç”¨æˆ·ID ==========
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        config = request.json
        
        # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ ID
        import uuid
        session_id = str(uuid.uuid4())
        
        # ========== è®°å½•è®­ç»ƒä¼šè¯åˆ°æ•°æ®åº“ ==========
        session_manager = get_session_manager()
        if session_manager:
            try:
                session_manager.create_session(
                    user_id=user_id,
                    session_id=session_id,
                    model_type=config.get('model', 'attention'),
                    problem_type=config.get('problem', 'tsp'),
                    config=json.dumps(config)
                )
            except Exception as e:
                print(f"è®°å½•è®­ç»ƒä¼šè¯å¤±è´¥: {str(e)}")
        
        # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
        training_queues[session_id] = Queue()
        
        # æ ¹æ® RL4CO æ˜¯å¦å¯ç”¨é€‰æ‹©è®­ç»ƒå‡½æ•°
        if RL4CO_AVAILABLE:
            training_func = real_rl4co_training
            mode = "çœŸå®è®­ç»ƒæ¨¡å¼"
        else:
            training_func = simulate_training
            mode = "æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼"
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨è®­ç»ƒï¼ˆä¼ å…¥user_idï¼‰
        training_thread = threading.Thread(
            target=training_func,
            args=(config, session_id, user_id),  # ========== æ·»åŠ user_idå‚æ•° ==========
            daemon=True
        )
        training_thread.start()
        
        return jsonify({
            'success': True,
            'session_id': session_id,
            'message': f'è®­ç»ƒå·²å¯åŠ¨ ({mode})'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'å¯åŠ¨è®­ç»ƒå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/training_progress/<session_id>')
def training_progress(session_id):
    """ä½¿ç”¨ Server-Sent Events (SSE) æ¨é€è®­ç»ƒè¿›åº¦"""
    def generate():
        if session_id not in training_queues:
            yield f"data: {json.dumps({'type': 'error', 'message': 'æ— æ•ˆçš„ä¼šè¯ ID'})}\n\n"
            return
        
        queue = training_queues[session_id]
        
        while True:
            try:
                # ä»é˜Ÿåˆ—ä¸­è·å–æ¶ˆæ¯ï¼ˆé˜»å¡ç­‰å¾…ï¼‰
                message = queue.get(timeout=1)
                yield f"data: {message}\n\n"
                
                # å¦‚æœæ”¶åˆ°å®Œæˆæˆ–é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™ç»“æŸæµ
                data = json.loads(message)
                if data['type'] in ['complete', 'error']:
                    break
                    
            except:
                # è¶…æ—¶æˆ–é˜Ÿåˆ—ä¸ºç©ºï¼Œå‘é€å¿ƒè·³
                if session_id in training_status:
                    if training_status[session_id]['status'] == 'completed':
                        break
                yield f"data: {json.dumps({'type': 'heartbeat'})}\n\n"
    
    return Response(generate(), mimetype='text/event-stream')


@app.route('/api/training_status/<session_id>')
def get_training_status(session_id):
    """è·å–å½“å‰è®­ç»ƒçŠ¶æ€"""
    if session_id in training_status:
        return jsonify({
            'success': True,
            'status': training_status[session_id]
        })
    else:
        return jsonify({
            'success': False,
            'message': 'æœªæ‰¾åˆ°è®­ç»ƒä¼šè¯'
        }), 404


@app.route('/api/list_files', methods=['GET'])
@login_required
def list_training_files():
    """åˆ—å‡ºå½“å‰ç”¨æˆ·çš„è®­ç»ƒäº§ç”Ÿçš„æ–‡ä»¶ - éœ€è¦ç™»å½•"""
    try:
        # ========== è·å–å½“å‰ç”¨æˆ·IDï¼Œåªæ˜¾ç¤ºè¯¥ç”¨æˆ·çš„æ–‡ä»¶ ==========
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        # ========== ä»æ•°æ®åº“è·å–ç”¨æˆ·æ–‡ä»¶åˆ—è¡¨ ==========
        file_manager = get_file_manager()
        if file_manager:
            try:
                user_files = file_manager.get_user_files(user_id)
                storage_stats = file_manager.get_user_storage_stats(user_id)
                
                files_info = {
                    'plots': [],
                    'checkpoints': [],
                    'total_size': storage_stats['total_mb'] if storage_stats else 0,
                    'total_count': storage_stats['total_files'] if storage_stats else 0
                }
                
                for file_record in user_files:
                    file_info = {
                        'id': file_record['id'],
                        'name': file_record['file_name'],
                        'type': file_record['file_type'],
                        'size': file_record['file_size'],
                        'size_mb': round(file_record['file_size'] / (1024 * 1024), 2),
                        'path': f"/static/model_plots/user_{user_id}/{file_record['file_name']}",
                        'session_id': file_record['session_id'],
                        'create_time': file_record['create_time'].strftime('%Y-%m-%d %H:%M')
                    }
                    
                    if file_record['file_type'] in ['plot', 'animation', 'curve']:
                        files_info['plots'].append(file_info)
                    elif file_record['file_type'] == 'checkpoint':
                        files_info['checkpoints'].append(file_info)
                
                return jsonify({
                    'success': True,
                    'files': files_info
                })
                
            except Exception as e:
                print(f"ä»æ•°æ®åº“è·å–æ–‡ä»¶å¤±è´¥: {str(e)}")
                # é™çº§åˆ°æ–‡ä»¶ç³»ç»Ÿæ‰«æ
                pass
        
        # ========== é™çº§æ–¹æ¡ˆï¼šç›´æ¥æ‰«æç”¨æˆ·ç›®å½• ==========
        files_info = {
            'plots': [],
            'checkpoints': [],
            'total_size': 0
        }
        
        USER_PLOTS_DIR = get_user_plot_dir(user_id)
        USER_CHECKPOINTS_DIR = get_user_checkpoint_dir(user_id)
        
        # åˆ—å‡ºå¯è§†åŒ–å›¾ç‰‡æ–‡ä»¶
        if os.path.exists(USER_PLOTS_DIR):
            for filename in os.listdir(USER_PLOTS_DIR):
                file_path = os.path.join(USER_PLOTS_DIR, filename)
                if os.path.isfile(file_path):
                    file_size = os.path.getsize(file_path)
                    file_type = 'unknown'
                    
                    if filename.startswith('comparison_'):
                        file_type = 'comparison'
                    elif filename.startswith('animation_'):
                        file_type = 'animation'
                    elif filename.startswith('training_curves_'):
                        file_type = 'training_curve'
                    
                    files_info['plots'].append({
                        'name': filename,
                        'type': file_type,
                        'size': file_size,
                        'size_mb': round(file_size / (1024 * 1024), 2),
                        'path': f'/static/model_plots/user_{user_id}/{filename}',
                        'modified': os.path.getmtime(file_path)
                    })
                    files_info['total_size'] += file_size
        
        # åˆ—å‡ºæ£€æŸ¥ç‚¹æ–‡ä»¶
        if os.path.exists(CHECKPOINTS_DIR):
            for filename in os.listdir(CHECKPOINTS_DIR):
                file_path = os.path.join(CHECKPOINTS_DIR, filename)
                if os.path.isfile(file_path) and filename.endswith('.ckpt'):
                    file_size = os.path.getsize(file_path)
                    files_info['checkpoints'].append({
                        'name': filename,
                        'type': 'checkpoint',
                        'size': file_size,
                        'size_mb': round(file_size / (1024 * 1024), 2),
                        'path': file_path,
                        'modified': os.path.getmtime(file_path)
                    })
                    files_info['total_size'] += file_size
        
        # æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åº
        files_info['plots'].sort(key=lambda x: x['modified'], reverse=True)
        files_info['checkpoints'].sort(key=lambda x: x['modified'], reverse=True)
        
        files_info['total_size_mb'] = round(files_info['total_size'] / (1024 * 1024), 2)
        files_info['total_count'] = len(files_info['plots']) + len(files_info['checkpoints'])
        
        return jsonify({
            'success': True,
            'files': files_info
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/delete_file', methods=['POST'])
@login_required
def delete_training_file():
    """åˆ é™¤æŒ‡å®šçš„è®­ç»ƒæ–‡ä»¶ - éœ€è¦ç™»å½•ä¸”åªèƒ½åˆ é™¤è‡ªå·±çš„æ–‡ä»¶"""
    try:
        # ========== è·å–å½“å‰ç”¨æˆ·ID ==========
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        data = request.json
        file_id = data.get('file_id')  # ========== ä½¿ç”¨file_idè€Œéfilename ==========
        filename = data.get('filename')  # å…¼å®¹æ—§ç‰ˆ
        
        # ========== ä½¿ç”¨æ•°æ®åº“æ–¹å¼åˆ é™¤ï¼ˆæ¨èï¼‰ ==========
        file_manager = get_file_manager()
        if file_id and file_manager:
            success, message = file_manager.delete_file(file_id, user_id)
            if success:
                return jsonify({
                    'success': True,
                    'message': message
                })
            else:
                return jsonify({
                    'success': False,
                    'message': message
                }), 403
        
        # ========== é™çº§æ–¹æ¡ˆï¼šç›´æ¥åˆ é™¤æ–‡ä»¶ï¼ˆå…¼å®¹ï¼‰ ==========
        if not filename:
            return jsonify({
                'success': False,
                'message': 'æœªæä¾›æ–‡ä»¶åæˆ–æ–‡ä»¶ID'
            }), 400
        
        file_type = data.get('file_type', 'plot')
        USER_PLOTS_DIR = get_user_plot_dir(user_id)
        USER_CHECKPOINTS_DIR = get_user_checkpoint_dir(user_id)
        
        # ç¡®å®šæ–‡ä»¶è·¯å¾„ï¼ˆç”¨æˆ·ä¸“å±ç›®å½•ï¼‰
        if file_type == 'checkpoint':
            file_path = os.path.join(USER_CHECKPOINTS_DIR, filename)
        else:
            file_path = os.path.join(USER_PLOTS_DIR, filename)
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨ç”¨æˆ·ç›®å½•å†…
        abs_file_path = os.path.abspath(file_path)
        abs_user_plots = os.path.abspath(USER_PLOTS_DIR)
        abs_user_checkpoints = os.path.abspath(USER_CHECKPOINTS_DIR)
        
        if not (abs_file_path.startswith(abs_user_plots) or abs_file_path.startswith(abs_user_checkpoints)):
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„æˆ–æ— æƒè®¿é—®'
            }), 403
        
        # åˆ é™¤æ–‡ä»¶
        if os.path.exists(file_path):
            os.remove(file_path)
            return jsonify({
                'success': True,
                'message': f'æ–‡ä»¶ {filename} å·²åˆ é™¤'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/download_checkpoint/<filename>')
@login_required
def download_checkpoint(filename):
    """ä¸‹è½½æ£€æŸ¥ç‚¹æ–‡ä»¶ - éœ€è¦ç™»å½•ä¸”åªèƒ½ä¸‹è½½è‡ªå·±çš„æ–‡ä»¶"""
    try:
        # ========== è·å–å½“å‰ç”¨æˆ·ID ==========
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        USER_CHECKPOINTS_DIR = get_user_checkpoint_dir(user_id)
        
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
        safe_filename = os.path.basename(filename)
        file_path = os.path.join(USER_CHECKPOINTS_DIR, safe_filename)
        
        # éªŒè¯æ–‡ä»¶è·¯å¾„åœ¨ç”¨æˆ·ç›®å½•å†…
        abs_file_path = os.path.abspath(file_path)
        abs_user_dir = os.path.abspath(USER_CHECKPOINTS_DIR)
        
        if not abs_file_path.startswith(abs_user_dir):
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„'
            }), 403
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return jsonify({
                'success': False,
                'message': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        # å‘é€æ–‡ä»¶
        from flask import send_file
        return send_file(
            file_path,
            as_attachment=True,
            download_name=safe_filename,
            mimetype='application/octet-stream'
        )
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'ä¸‹è½½å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/delete_by_session', methods=['POST'])
@login_required
def delete_by_session():
    """æ ¹æ®session_idåˆ é™¤ç›¸å…³çš„æ‰€æœ‰æ–‡ä»¶ - éœ€è¦ç™»å½•ä¸”åªèƒ½åˆ é™¤è‡ªå·±çš„æ–‡ä»¶"""
    try:
        # ========== è·å–å½“å‰ç”¨æˆ·ID ==========
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        data = request.json
        session_id = data.get('session_id')
        
        if not session_id:
            return jsonify({
                'success': False,
                'message': 'æœªæä¾›session_id'
            }), 400
        
        # å–å‰8ä½ä½œä¸ºæ–‡ä»¶åå‰ç¼€
        session_prefix = session_id[:8]
        deleted_files = []
        
        USER_PLOTS_DIR = get_user_plot_dir(user_id)
        
        # åˆ é™¤ç”¨æˆ·çš„å¯è§†åŒ–æ–‡ä»¶
        if os.path.exists(USER_PLOTS_DIR):
            for filename in os.listdir(USER_PLOTS_DIR):
                if session_prefix in filename:
                    file_path = os.path.join(USER_PLOTS_DIR, filename)
                    try:
                        os.remove(file_path)
                        deleted_files.append(filename)
                    except Exception as e:
                        print(f"åˆ é™¤æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
        
        return jsonify({
            'success': True,
            'message': f'å·²åˆ é™¤ {len(deleted_files)} ä¸ªæ–‡ä»¶',
            'deleted_files': deleted_files
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ‰¹é‡åˆ é™¤å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/clear_all_files', methods=['POST'])
@login_required
def clear_all_files():
    """æ¸…ç©ºå½“å‰ç”¨æˆ·çš„æ‰€æœ‰è®­ç»ƒæ–‡ä»¶ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
    try:
        # ========== è·å–å½“å‰ç”¨æˆ·ID ==========
        user_id = get_current_user_id()
        if not user_id:
            return jsonify({
                'success': False,
                'message': 'è¯·å…ˆç™»å½•'
            }), 401
        
        data = request.json
        confirm = data.get('confirm', False)
        
        if not confirm:
            return jsonify({
                'success': False,
                'message': 'éœ€è¦ç¡®è®¤æ“ä½œ'
            }), 400
        
        deleted_count = 0
        
        USER_PLOTS_DIR = get_user_plot_dir(user_id)
        USER_CHECKPOINTS_DIR = get_user_checkpoint_dir(user_id)
        
        # æ¸…ç©ºç”¨æˆ·çš„å¯è§†åŒ–æ–‡ä»¶
        if os.path.exists(USER_PLOTS_DIR):
            for filename in os.listdir(USER_PLOTS_DIR):
                file_path = os.path.join(USER_PLOTS_DIR, filename)
                if os.path.isfile(file_path):
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                    except Exception as e:
                        print(f"åˆ é™¤æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
        
        # æ¸…ç©ºç”¨æˆ·çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
        if os.path.exists(USER_CHECKPOINTS_DIR):
            for filename in os.listdir(USER_CHECKPOINTS_DIR):
                if filename.endswith('.ckpt'):
                    file_path = os.path.join(USER_CHECKPOINTS_DIR, filename)
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                    except Exception as e:
                        print(f"åˆ é™¤æ–‡ä»¶ {filename} å¤±è´¥: {str(e)}")
        
        # ========== åŒæ—¶æ¸…ç©ºæ•°æ®åº“è®°å½• ==========
        file_manager = get_file_manager()
        if file_manager:
            try:
                db = get_db()
                cursor = db.cursor()
                cursor.execute("DELETE FROM user_files WHERE user_id = %s", (user_id,))
                db.commit()
            except Exception as e:
                print(f"æ¸…ç©ºæ•°æ®åº“è®°å½•å¤±è´¥: {str(e)}")
        
        return jsonify({
            'success': True,
            'message': f'å·²æ¸…ç©ºæ‰€æœ‰æ–‡ä»¶ï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ¸…ç©ºæ–‡ä»¶å¤±è´¥: {str(e)}'
        }), 500


if __name__ == '__main__':
    app.run(debug=True)
